{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "766c21ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:14.662271Z",
     "iopub.status.busy": "2024-05-28T10:54:14.661851Z",
     "iopub.status.idle": "2024-05-28T10:54:19.751099Z",
     "shell.execute_reply": "2024-05-28T10:54:19.749942Z"
    },
    "papermill": {
     "duration": 5.104325,
     "end_time": "2024-05-28T10:54:19.753826",
     "exception": false,
     "start_time": "2024-05-28T10:54:14.649501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/aes-whls/aes_whls/pyphen-0.15.0-py3-none-any.whl\r\n",
      "Installing collected packages: pyphen\r\n",
      "Successfully installed pyphen-0.15.0\r\n",
      "Processing /kaggle/input/aes-whls/aes_whls/textstat-0.7.3-py3-none-any.whl\r\n",
      "Installing collected packages: textstat\r\n",
      "Successfully installed textstat-0.7.3\r\n"
     ]
    }
   ],
   "source": [
    "# Decomment this line of code if you already have those downloaded\n",
    "!pip install --no-index --no-deps /kaggle/input/aes-whls/aes_whls/pyphen-0.15.0-py3-none-any.whl\n",
    "!pip install --no-index --no-deps /kaggle/input/aes-whls/aes_whls/textstat-0.7.3-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba8e836",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:19.778532Z",
     "iopub.status.busy": "2024-05-28T10:54:19.778128Z",
     "iopub.status.idle": "2024-05-28T10:54:26.843327Z",
     "shell.execute_reply": "2024-05-28T10:54:26.842223Z"
    },
    "papermill": {
     "duration": 7.080926,
     "end_time": "2024-05-28T10:54:26.846076",
     "exception": false,
     "start_time": "2024-05-28T10:54:19.765150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Basic libary\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import re\n",
    "import optuna\n",
    "import textstat\n",
    "from optuna.samplers import TPESampler\n",
    "# cmap = plt.cm.get_cmap('coolwarm')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Use for pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score, make_scorer\n",
    "\n",
    "# Use for training model\n",
    "from scipy.stats import randint\n",
    "from nltk.tokenize import word_tokenize\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier \n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93907a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:26.869887Z",
     "iopub.status.busy": "2024-05-28T10:54:26.869270Z",
     "iopub.status.idle": "2024-05-28T10:54:27.692924Z",
     "shell.execute_reply": "2024-05-28T10:54:27.691931Z"
    },
    "papermill": {
     "duration": 0.838581,
     "end_time": "2024-05-28T10:54:27.695663",
     "exception": false,
     "start_time": "2024-05-28T10:54:26.857082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288ef627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:27.719110Z",
     "iopub.status.busy": "2024-05-28T10:54:27.718711Z",
     "iopub.status.idle": "2024-05-28T10:54:27.753914Z",
     "shell.execute_reply": "2024-05-28T10:54:27.752726Z"
    },
    "papermill": {
     "duration": 0.049858,
     "end_time": "2024-05-28T10:54:27.756412",
     "exception": false,
     "start_time": "2024-05-28T10:54:27.706554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17307 entries, 0 to 17306\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   full_text  17307 non-null  object\n",
      " 1   score      17307 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 270.5+ KB\n"
     ]
    }
   ],
   "source": [
    "essay_id_dropped = df_train['essay_id']\n",
    "df_train = df_train.drop('essay_id', axis = 1)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800e04be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:27.779815Z",
     "iopub.status.busy": "2024-05-28T10:54:27.779360Z",
     "iopub.status.idle": "2024-05-28T10:54:27.793764Z",
     "shell.execute_reply": "2024-05-28T10:54:27.792721Z"
    },
    "papermill": {
     "duration": 0.028869,
     "end_time": "2024-05-28T10:54:27.796105",
     "exception": false,
     "start_time": "2024-05-28T10:54:27.767236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Many people have car where they live. The thin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a scientist at NASA that is discussing th...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>People always wish they had the same technolog...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We all heard about Venus, the planet without a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  score\n",
       "0  Many people have car where they live. The thin...      3\n",
       "1  I am a scientist at NASA that is discussing th...      3\n",
       "2  People always wish they had the same technolog...      4\n",
       "3  We all heard about Venus, the planet without a...      4\n",
       "4  Dear, State Senator\\n\\nThis is a letter to arg...      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de3da4bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:27.820567Z",
     "iopub.status.busy": "2024-05-28T10:54:27.820205Z",
     "iopub.status.idle": "2024-05-28T10:54:27.854523Z",
     "shell.execute_reply": "2024-05-28T10:54:27.853491Z"
    },
    "papermill": {
     "duration": 0.049507,
     "end_time": "2024-05-28T10:54:27.856808",
     "exception": false,
     "start_time": "2024-05-28T10:54:27.807301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def removeHTML(x):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',x)\n",
    "\n",
    "\n",
    "cList = {\n",
    "    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "    # \"he'd\": \"he would\",  ## --> he had or he would\n",
    "    \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\", \n",
    "    \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\n",
    "    # \"I'd\": \"I would\",   ## --> I had or I would\n",
    "    \"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\n",
    "    # \"it'd\": \"it had\",   ## --> It had or It would\n",
    "    \"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\n",
    "    # \"she'd\": \"she would\",   ## --> It had or It would\n",
    "    \"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\"so's\": \"so is\",\n",
    "    # \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\"that's\": \"that is\",\n",
    "    # \"there'd\": \"there had\",\n",
    "    \"there'd've\": \"there would have\",\"there's\": \"there is\",\n",
    "    # \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\"wasn't\": \"was not\",\"weren't\": \"were not\",\n",
    "    # \"we'd\": \"we had\",\n",
    "    \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n",
    "    \"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\n",
    "    \"you're\": \"you are\",  \"you've\": \"you have\"\n",
    "}\n",
    "c_re = re.compile('(%s)' % '|'.join(cList.keys()))\n",
    "\n",
    "def expandContractions(text):\n",
    "    def replace(match):\n",
    "        return cList[match.group(0)]\n",
    "    return c_re.sub(replace, text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Remove all punctuation from the input text.\n",
    "    \n",
    "    Args:\n",
    "    - text (str): The input text.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The text with punctuation removed.\n",
    "    \"\"\"\n",
    "    # string.punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def dataPreprocessing(x):\n",
    "    # Convert words to lowercase\n",
    "    x = x.lower()\n",
    "    # Remove HTML\n",
    "    x = removeHTML(x)\n",
    "    # Delete strings starting with @\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    # Delete Numbers\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    # Delete URL\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    # Replace consecutive empty spaces with a single space character\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = re.sub(r'\\xa0', '', x)\n",
    "    # Remove empty characters at the beginning and end\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "def dataPreprocessing_w_contract(x):\n",
    "    # Convert words to lowercase\n",
    "    x = x.lower()\n",
    "    # Remove HTML\n",
    "    x = removeHTML(x)\n",
    "    # Delete strings starting with @\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    # Delete Numbers\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    # Delete URL\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    # Replace consecutive empty spaces with a single space character\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    x = expandContractions(x)\n",
    "    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    # Remove empty characters at the beginning and end\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "def dataPreprocessing_w_punct_remove(x):\n",
    "    # Convert words to lowercase\n",
    "    x = x.lower()\n",
    "    # Remove HTML\n",
    "    x = removeHTML(x)\n",
    "    # Delete strings starting with @\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    # Delete Numbers\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    # Delete URL\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    # Replace consecutive empty spaces with a single space character\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = remove_punctuation(x)\n",
    "    # Remove empty characters at the beginning and end\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "def dataPreprocessing_w_contract_punct_remove(x):\n",
    "    # Convert words to lowercase\n",
    "    x = x.lower()\n",
    "    # Remove HTML\n",
    "    x = removeHTML(x)\n",
    "    # Delete strings starting with @\n",
    "    x = re.sub(\"@\\w+\", '',x)\n",
    "    # Delete Numbers\n",
    "    x = re.sub(\"'\\d+\", '',x)\n",
    "    x = re.sub(\"\\d+\", '',x)\n",
    "    # Delete URL\n",
    "    x = re.sub(\"http\\w+\", '',x)\n",
    "    # Replace consecutive empty spaces with a single space character\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    x = expandContractions(x)\n",
    "    # Replace consecutive commas and periods with one comma and period character\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = remove_punctuation(x)\n",
    "    # Remove empty characters at the beginning and end\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6287dbaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:27.882798Z",
     "iopub.status.busy": "2024-05-28T10:54:27.882323Z",
     "iopub.status.idle": "2024-05-28T10:54:27.892141Z",
     "shell.execute_reply": "2024-05-28T10:54:27.891007Z"
    },
    "papermill": {
     "duration": 0.02504,
     "end_time": "2024-05-28T10:54:27.894446",
     "exception": false,
     "start_time": "2024-05-28T10:54:27.869406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def textstat_features(text):\n",
    "    features = {}\n",
    "    features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n",
    "    features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n",
    "    features['smog_index'] = textstat.smog_index(text)\n",
    "    features['coleman_liau_index'] = textstat.coleman_liau_index(text)\n",
    "    features['automated_readability_index'] = textstat.automated_readability_index(text)\n",
    "    features['dale_chall_readability_score'] = textstat.dale_chall_readability_score(text)\n",
    "    features['difficult_words'] = textstat.difficult_words(text)\n",
    "    features['linsear_write_formula'] = textstat.linsear_write_formula(text)\n",
    "    features['gunning_fog'] = textstat.gunning_fog(text)\n",
    "    features['text_standard'] = textstat.text_standard(text, float_output=True)\n",
    "    features['spache_readability'] = textstat.spache_readability(text)\n",
    "    features['mcalpine_efg_time'] = textstat.reading_time(text)\n",
    "    features['syllablaw'] = textstat.mcalpine_eflaw(text)\n",
    "    features['readinle_count'] = textstat.syllable_count(text)\n",
    "    features['lexicon_count'] = textstat.lexicon_count(text)\n",
    "    features['monosyllabcount'] = textstat.monosyllabcount(text)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f826c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:27.918864Z",
     "iopub.status.busy": "2024-05-28T10:54:27.918171Z",
     "iopub.status.idle": "2024-05-28T10:54:27.932660Z",
     "shell.execute_reply": "2024-05-28T10:54:27.931621Z"
    },
    "papermill": {
     "duration": 0.029376,
     "end_time": "2024-05-28T10:54:27.934976",
     "exception": false,
     "start_time": "2024-05-28T10:54:27.905600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of words\n",
    "import string\n",
    "def preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Length\n",
    "    df['essay_length'] = df['full_text'].str.len()\n",
    "\n",
    "    # Sentences count\n",
    "    # Adding a new column 'sentences_count' that counts the sentences in 'full_text'\n",
    "    df['sentences_count'] = df['full_text'].str.count(r'\\.')\n",
    "\n",
    "    # Paragraph count\n",
    "    # Adding a new column 'paragraph_count' that counts the paragraphs in 'full_text'\n",
    "    df['paragraph_count'] = df['full_text'].str.count(r'\\n') + 1\n",
    "    \n",
    "    df[\"text_tokens\"] = df[\"full_text\"].apply(lambda x: word_tokenize(x))\n",
    "    df[\"word_count\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n",
    "    df[\"unique_word_count\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n",
    "    df.drop(columns=[\"text_tokens\"], inplace=True)\n",
    "    \n",
    "    df[\"processed_text\"] = df[\"full_text\"].apply(lambda x: dataPreprocessing(x))\n",
    "    df[\"text_tokens\"] = df[\"processed_text\"].apply(lambda x: word_tokenize(x))\n",
    "    df[\"text_length_p\"] = df[\"processed_text\"].apply(lambda x: len(x))\n",
    "    df[\"word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n",
    "    df[\"unique_word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n",
    "    \n",
    "    # Applying textstat features\n",
    "    df['textstat_features'] = df['processed_text'].apply(textstat_features)\n",
    "    textstat_df = pd.DataFrame(df['textstat_features'].tolist())\n",
    "    df = pd.concat([df, textstat_df], axis=1)\n",
    "\n",
    "    df.drop(columns=[\"processed_text\", \"text_tokens\", \"textstat_features\"], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n', ' ', text)  # Loại bỏ xuống dòng\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ ký tự đặc biệt\n",
    "    text = re.sub(r'\\xa0', '', text)\n",
    "    text = text.lower()  # Chuyển thành chữ thường\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0c5945",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:54:27.959964Z",
     "iopub.status.busy": "2024-05-28T10:54:27.959105Z",
     "iopub.status.idle": "2024-05-28T10:59:40.204882Z",
     "shell.execute_reply": "2024-05-28T10:59:40.203611Z"
    },
    "papermill": {
     "duration": 312.261686,
     "end_time": "2024-05-28T10:59:40.207949",
     "exception": false,
     "start_time": "2024-05-28T10:54:27.946263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = preprocess_df(df_train)\n",
    "df_train['clean_text'] = df_train['full_text'].apply(clean_text)\n",
    "df_train = df_train.drop('full_text', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b00775bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:59:40.232484Z",
     "iopub.status.busy": "2024-05-28T10:59:40.232128Z",
     "iopub.status.idle": "2024-05-28T10:59:40.258311Z",
     "shell.execute_reply": "2024-05-28T10:59:40.257299Z"
    },
    "papermill": {
     "duration": 0.041676,
     "end_time": "2024-05-28T10:59:40.260966",
     "exception": false,
     "start_time": "2024-05-28T10:59:40.219290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>essay_length</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>paragraph_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>text_length_p</th>\n",
       "      <th>word_count_p</th>\n",
       "      <th>unique_word_count_p</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>...</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>text_standard</th>\n",
       "      <th>spache_readability</th>\n",
       "      <th>mcalpine_efg_time</th>\n",
       "      <th>syllablaw</th>\n",
       "      <th>readinle_count</th>\n",
       "      <th>lexicon_count</th>\n",
       "      <th>monosyllabcount</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>545</td>\n",
       "      <td>2677</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "      <td>2640</td>\n",
       "      <td>539</td>\n",
       "      <td>227</td>\n",
       "      <td>58.69</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.08</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>31.58</td>\n",
       "      <td>53.4</td>\n",
       "      <td>624</td>\n",
       "      <td>489</td>\n",
       "      <td>396</td>\n",
       "      <td>many people have car where they live the thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>371</td>\n",
       "      <td>1669</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>168</td>\n",
       "      <td>1663</td>\n",
       "      <td>371</td>\n",
       "      <td>152</td>\n",
       "      <td>87.55</td>\n",
       "      <td>...</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>19.57</td>\n",
       "      <td>25.7</td>\n",
       "      <td>398</td>\n",
       "      <td>332</td>\n",
       "      <td>275</td>\n",
       "      <td>i am a scientist at nasa that is discussing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>605</td>\n",
       "      <td>3077</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>243</td>\n",
       "      <td>3065</td>\n",
       "      <td>605</td>\n",
       "      <td>231</td>\n",
       "      <td>65.15</td>\n",
       "      <td>...</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>36.96</td>\n",
       "      <td>32.6</td>\n",
       "      <td>767</td>\n",
       "      <td>550</td>\n",
       "      <td>417</td>\n",
       "      <td>people always wish they had the same technolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>511</td>\n",
       "      <td>2701</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>241</td>\n",
       "      <td>2674</td>\n",
       "      <td>502</td>\n",
       "      <td>223</td>\n",
       "      <td>58.62</td>\n",
       "      <td>...</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>11.85</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.32</td>\n",
       "      <td>32.74</td>\n",
       "      <td>28.9</td>\n",
       "      <td>678</td>\n",
       "      <td>441</td>\n",
       "      <td>284</td>\n",
       "      <td>we all heard about venus the planet without al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>418</td>\n",
       "      <td>2208</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>156</td>\n",
       "      <td>2184</td>\n",
       "      <td>417</td>\n",
       "      <td>148</td>\n",
       "      <td>54.76</td>\n",
       "      <td>...</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>12.61</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.61</td>\n",
       "      <td>26.62</td>\n",
       "      <td>35.6</td>\n",
       "      <td>561</td>\n",
       "      <td>372</td>\n",
       "      <td>240</td>\n",
       "      <td>dear state senator  this is a letter to argue ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   score  word_count  essay_length  sentences_count  paragraph_count  \\\n",
       "0      3         545          2677               13                1   \n",
       "1      3         371          1669               19                9   \n",
       "2      4         605          3077               24                7   \n",
       "3      4         511          2701               23                9   \n",
       "4      3         418          2208               15               11   \n",
       "\n",
       "   unique_word_count  text_length_p  word_count_p  unique_word_count_p  \\\n",
       "0                248           2640           539                  227   \n",
       "1                168           1663           371                  152   \n",
       "2                243           3065           605                  231   \n",
       "3                241           2674           502                  223   \n",
       "4                156           2184           417                  148   \n",
       "\n",
       "   flesch_reading_ease  ...  linsear_write_formula  gunning_fog  \\\n",
       "0                58.69  ...              13.000000        17.08   \n",
       "1                87.55  ...               6.714286         7.48   \n",
       "2                65.15  ...              15.500000        11.49   \n",
       "3                58.62  ...              15.750000        11.85   \n",
       "4                54.76  ...              19.666667        12.61   \n",
       "\n",
       "   text_standard  spache_readability  mcalpine_efg_time  syllablaw  \\\n",
       "0           12.0                7.20              31.58       53.4   \n",
       "1            7.0                3.92              19.57       25.7   \n",
       "2           12.0                5.12              36.96       32.6   \n",
       "3           13.0                5.32              32.74       28.9   \n",
       "4           13.0                5.61              26.62       35.6   \n",
       "\n",
       "   readinle_count  lexicon_count  monosyllabcount  \\\n",
       "0             624            489              396   \n",
       "1             398            332              275   \n",
       "2             767            550              417   \n",
       "3             678            441              284   \n",
       "4             561            372              240   \n",
       "\n",
       "                                          clean_text  \n",
       "0  many people have car where they live the thing...  \n",
       "1  i am a scientist at nasa that is discussing th...  \n",
       "2  people always wish they had the same technolog...  \n",
       "3  we all heard about venus the planet without al...  \n",
       "4  dear state senator  this is a letter to argue ...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8494f61e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:59:40.285694Z",
     "iopub.status.busy": "2024-05-28T10:59:40.285019Z",
     "iopub.status.idle": "2024-05-28T10:59:40.300141Z",
     "shell.execute_reply": "2024-05-28T10:59:40.298994Z"
    },
    "papermill": {
     "duration": 0.030311,
     "end_time": "2024-05-28T10:59:40.303013",
     "exception": false,
     "start_time": "2024-05-28T10:59:40.272702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17307 entries, 0 to 17306\n",
      "Data columns (total 26 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   score                         17307 non-null  int64  \n",
      " 1   word_count                    17307 non-null  int64  \n",
      " 2   essay_length                  17307 non-null  int64  \n",
      " 3   sentences_count               17307 non-null  int64  \n",
      " 4   paragraph_count               17307 non-null  int64  \n",
      " 5   unique_word_count             17307 non-null  int64  \n",
      " 6   text_length_p                 17307 non-null  int64  \n",
      " 7   word_count_p                  17307 non-null  int64  \n",
      " 8   unique_word_count_p           17307 non-null  int64  \n",
      " 9   flesch_reading_ease           17307 non-null  float64\n",
      " 10  flesch_kincaid_grade          17307 non-null  float64\n",
      " 11  smog_index                    17307 non-null  float64\n",
      " 12  coleman_liau_index            17307 non-null  float64\n",
      " 13  automated_readability_index   17307 non-null  float64\n",
      " 14  dale_chall_readability_score  17307 non-null  float64\n",
      " 15  difficult_words               17307 non-null  int64  \n",
      " 16  linsear_write_formula         17307 non-null  float64\n",
      " 17  gunning_fog                   17307 non-null  float64\n",
      " 18  text_standard                 17307 non-null  float64\n",
      " 19  spache_readability            17307 non-null  float64\n",
      " 20  mcalpine_efg_time             17307 non-null  float64\n",
      " 21  syllablaw                     17307 non-null  float64\n",
      " 22  readinle_count                17307 non-null  int64  \n",
      " 23  lexicon_count                 17307 non-null  int64  \n",
      " 24  monosyllabcount               17307 non-null  int64  \n",
      " 25  clean_text                    17307 non-null  object \n",
      "dtypes: float64(12), int64(13), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "180e3562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:59:40.328234Z",
     "iopub.status.busy": "2024-05-28T10:59:40.327532Z",
     "iopub.status.idle": "2024-05-28T10:59:40.332217Z",
     "shell.execute_reply": "2024-05-28T10:59:40.331123Z"
    },
    "papermill": {
     "duration": 0.019637,
     "end_time": "2024-05-28T10:59:40.334452",
     "exception": false,
     "start_time": "2024-05-28T10:59:40.314815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rows_to_drop = df_train.query('sentences_count > 60 | (sentences_count > 50 & score == 1)').index\n",
    "\n",
    "# # Xóa các dòng có index tương ứng\n",
    "\n",
    "# df_train.drop(rows_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "979ad803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:59:40.360893Z",
     "iopub.status.busy": "2024-05-28T10:59:40.360504Z",
     "iopub.status.idle": "2024-05-28T10:59:40.364946Z",
     "shell.execute_reply": "2024-05-28T10:59:40.363991Z"
    },
    "papermill": {
     "duration": 0.020876,
     "end_time": "2024-05-28T10:59:40.367129",
     "exception": false,
     "start_time": "2024-05-28T10:59:40.346253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rows_to_drop = df_train.query('paragraph_count > 80 | (paragraph_count > 55 & score == 1 ) | (paragraph_count >60 & score == 2 ) | (paragraph_count > 30  & score == 5) | (paragraph_count > 25  & score == 6)').index\n",
    "\n",
    "# # Xóa các dòng có index tương ứng\n",
    "\n",
    "# df_train.drop(rows_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c92218d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T10:59:40.393452Z",
     "iopub.status.busy": "2024-05-28T10:59:40.392656Z",
     "iopub.status.idle": "2024-05-28T11:00:12.258276Z",
     "shell.execute_reply": "2024-05-28T11:00:12.257213Z"
    },
    "papermill": {
     "duration": 31.892684,
     "end_time": "2024-05-28T11:00:12.272176",
     "exception": false,
     "start_time": "2024-05-28T10:59:40.379492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running...\n",
      "This Pipeline is done\n"
     ]
    }
   ],
   "source": [
    "# Decomment if want to use Pipeline again\n",
    "print(\"Start running...\")\n",
    "# Define transformers for numerical and categorical columns\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n",
    "])\n",
    "\n",
    "# Add text vectorization step\n",
    "text_vectorizer = TfidfVectorizer(\n",
    "    encoding='utf-8',\n",
    "    ngram_range=(1, 3),\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    min_df=0.05,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('vectorizer', text_vectorizer)\n",
    "])\n",
    "\n",
    "# Update categorical and numerical columns\n",
    "numerical_columns = df_train.select_dtypes('int64').columns\n",
    "categorical_columns = df_train.select_dtypes('object').columns\n",
    "\n",
    "# Remove target variable from numerical columns\n",
    "numerical_columns = numerical_columns.drop('score')\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('text', text_transformer, 'clean_text')  # Include the 'clean_text' column\n",
    "    ],remainder = 'passthrough')\n",
    "\n",
    "# Create a pipeline with the preprocessor\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)])\n",
    "\n",
    "# Apply the pipeline to your dataset\n",
    "X = df_train.drop('score', axis=1)\n",
    "y = np.log(df_train['score']) #normalize dependent variable \n",
    "X_preprocessed = pipeline.fit_transform(X)\n",
    "print(\"This Pipeline is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768d7cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:00:12.297113Z",
     "iopub.status.busy": "2024-05-28T11:00:12.296357Z",
     "iopub.status.idle": "2024-05-28T11:00:12.301433Z",
     "shell.execute_reply": "2024-05-28T11:00:12.300419Z"
    },
    "papermill": {
     "duration": 0.020392,
     "end_time": "2024-05-28T11:00:12.303822",
     "exception": false,
     "start_time": "2024-05-28T11:00:12.283430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer(\n",
    "#     encoding='utf-8',\n",
    "#     ngram_range=(1, 3),\n",
    "#     strip_accents='unicode',\n",
    "#     analyzer='word',\n",
    "#     min_df=0.05,\n",
    "#     max_df=0.95,\n",
    "#     sublinear_tf=True\n",
    "# )\n",
    "\n",
    "# train_vectorized = pd.DataFrame(\n",
    "#     vectorizer.fit_transform(df_train['full_text']).toarray(),\n",
    "#     columns=[f\"tfidf_{str(f)}\" for f in vectorizer.get_feature_names_out()],\n",
    "# )\n",
    "\n",
    "# train_vectorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975e4263",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:00:12.328570Z",
     "iopub.status.busy": "2024-05-28T11:00:12.328219Z",
     "iopub.status.idle": "2024-05-28T11:00:12.333084Z",
     "shell.execute_reply": "2024-05-28T11:00:12.331739Z"
    },
    "papermill": {
     "duration": 0.0197,
     "end_time": "2024-05-28T11:00:12.335351",
     "exception": false,
     "start_time": "2024-05-28T11:00:12.315651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = pd.concat([df_train, train_vectorized], axis=1).drop(columns=[\"full_text\", \"score\", 'clean_text'], axis=1)\n",
    "# y = df_train[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aab9dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:00:12.360086Z",
     "iopub.status.busy": "2024-05-28T11:00:12.359419Z",
     "iopub.status.idle": "2024-05-28T11:00:13.375768Z",
     "shell.execute_reply": "2024-05-28T11:00:13.374703Z"
    },
    "papermill": {
     "duration": 1.031847,
     "end_time": "2024-05-28T11:00:13.378443",
     "exception": false,
     "start_time": "2024-05-28T11:00:12.346596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "# Use for vectorize\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#                                                     test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eae551ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:00:13.404037Z",
     "iopub.status.busy": "2024-05-28T11:00:13.403606Z",
     "iopub.status.idle": "2024-05-28T11:00:13.412439Z",
     "shell.execute_reply": "2024-05-28T11:00:13.411358Z"
    },
    "papermill": {
     "duration": 0.024357,
     "end_time": "2024-05-28T11:00:13.414884",
     "exception": false,
     "start_time": "2024-05-28T11:00:13.390527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = 2.998\n",
    "b = 1.092\n",
    "# idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    y_true = y_true + a\n",
    "    y_pred = (y_pred + a).clip(1, 6).round()\n",
    "    qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "    return 'QWK', qwk, True\n",
    "\n",
    "# metric and objective based on public notebooks\n",
    "def qwk_obj(y_true, y_pred):\n",
    "    labels = y_true + a\n",
    "    preds = y_pred + a\n",
    "    preds = preds.clip(1, 6)\n",
    "    f = 1/2*np.sum((preds-labels)**2)\n",
    "    g = 1/2*np.sum((preds-a)**2+b)\n",
    "    df = preds - labels\n",
    "    dg = preds - a\n",
    "    grad = (df/g - f*dg/g**2)*len(labels)\n",
    "    hess = np.ones(len(labels))\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96b2ee40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:00:13.440620Z",
     "iopub.status.busy": "2024-05-28T11:00:13.440229Z",
     "iopub.status.idle": "2024-05-28T11:00:13.445859Z",
     "shell.execute_reply": "2024-05-28T11:00:13.444933Z"
    },
    "papermill": {
     "duration": 0.020874,
     "end_time": "2024-05-28T11:00:13.448040",
     "exception": false,
     "start_time": "2024-05-28T11:00:13.427166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f1_scores = []\n",
    "# kappa_scores = []\n",
    "# predictions = []\n",
    "# # Define the models\n",
    "# models = {\n",
    "#     'XGBoost': XGBRegressor(random_state=42)\n",
    "# }\n",
    "\n",
    "# # Define the hyperparameter grids for each model\n",
    "# param_grids = {\n",
    "#     'XGBoost': {\n",
    "#         'n_estimators': [1024],\n",
    "#         'learning_rate': [0.1],\n",
    "#         'max_depth': [8],\n",
    "#         'subsample': [0.5],\n",
    "# #         'colsample_bytree': [0.5]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # 3-fold cross-validation\n",
    "# cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# # Train and tune the models\n",
    "# grids = {}\n",
    "# for model_name, model in models.items():\n",
    "#     grids[model_name] = GridSearchCV(estimator=model, param_grid=param_grids[model_name], \n",
    "#                                cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "#     grids[model_name].fit(X_train, y_train, eval_metric=quadratic_weighted_kappa)\n",
    "#     best_params = grids[model_name].best_params_\n",
    "#     best_score = np.sqrt(-1 * grids[model_name].best_score_)\n",
    "    \n",
    "#     print(f'Best parameters for {model_name}: {best_params}')\n",
    "#     print(f'Best RMSE for {model_name}: {best_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a44ef0a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:00:13.473496Z",
     "iopub.status.busy": "2024-05-28T11:00:13.472579Z",
     "iopub.status.idle": "2024-05-28T11:04:23.437577Z",
     "shell.execute_reply": "2024-05-28T11:04:23.436462Z"
    },
    "papermill": {
     "duration": 249.992475,
     "end_time": "2024-05-28T11:04:23.452172",
     "exception": false,
     "start_time": "2024-05-28T11:00:13.459697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None,\n",
       "             objective=&lt;function qwk_obj at 0x7d2af2448af0&gt;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None,\n",
       "             objective=&lt;function qwk_obj at 0x7d2af2448af0&gt;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None,\n",
       "             objective=<function qwk_obj at 0x7d2af2448af0>, ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Start running...\")\n",
    "\n",
    "# # Define the hyperparameter grids for each model\n",
    "# param_grids = {\n",
    "#     \"n_estimators\": randint(100, 500),\n",
    "#     \"learning_rate\": round(np.random.random(),1),\n",
    "#     \"max_depth\": randint(1, 9),\n",
    "#     \"subsample\": round(np.random.random(),1),\n",
    "#     \"max_features\": randint(1, 9),\n",
    "# }\n",
    "\n",
    "xgb_regressor = xgb.XGBRegressor(\n",
    "    objective=qwk_obj,  # Use custom QWK objective function\n",
    "    n_estimators= 100,\n",
    "    learning_rate= 0.1,\n",
    "    max_depth= 8,\n",
    "    subsample= 0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_regressor.fit(X_train, y_train, eval_metric=quadratic_weighted_kappa)\n",
    "# # Make predictions on the validation set\n",
    "# y_test_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "# # Convert predictions back to the original scale\n",
    "# # y_test_pred_original = np.exp(y_test_pred)\n",
    "# y_test = y_test + a\n",
    "# y_test_pred = (y_test_pred + a).clip(1, 6).round()\n",
    "\n",
    "\n",
    "# # Calculate QWK on the validation set\n",
    "# qwk_score = cohen_kappa_score(y_test, y_test_pred_original.round(), weights=\"quadratic\")\n",
    "# print(f\"Validation QWK Score: {qwk_score:.4f}\")\n",
    "\n",
    "# score = quadratic_weighted_kappa(y_test, y_pred)\n",
    "# print(f\"Train QWK: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83dd8ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:23.478555Z",
     "iopub.status.busy": "2024-05-28T11:04:23.477874Z",
     "iopub.status.idle": "2024-05-28T11:04:23.748548Z",
     "shell.execute_reply": "2024-05-28T11:04:23.747445Z"
    },
    "papermill": {
     "duration": 0.287157,
     "end_time": "2024-05-28T11:04:23.751339",
     "exception": false,
     "start_time": "2024-05-28T11:04:23.464182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12696    1.098612\n",
      "4625     1.098612\n",
      "733      1.098612\n",
      "16885    1.098612\n",
      "3334     1.386294\n",
      "           ...   \n",
      "16145    0.000000\n",
      "4229     0.693147\n",
      "4313     0.693147\n",
      "934      0.693147\n",
      "5058     0.693147\n",
      "Name: score, Length: 3462, dtype: float64\n",
      "[1.2824432  1.3152418  0.89939964 ... 0.89838845 0.72496426 0.7064404 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_regressor.predict(X_test)\n",
    "print(y_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be57ba54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:23.777997Z",
     "iopub.status.busy": "2024-05-28T11:04:23.777563Z",
     "iopub.status.idle": "2024-05-28T11:04:24.054096Z",
     "shell.execute_reply": "2024-05-28T11:04:24.052987Z"
    },
    "papermill": {
     "duration": 0.293308,
     "end_time": "2024-05-28T11:04:24.056695",
     "exception": false,
     "start_time": "2024-05-28T11:04:23.763387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.0\n",
      "Train QWK: 0.018538903203426216\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "y_pred = y_pred + a\n",
    "y_pred = y_pred.clip(1, 6).round()\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "# Calculate the F1 score\n",
    "f1_fold = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 score: {f1_fold}')\n",
    "\n",
    "# Calculate the Cohen's kappa score\n",
    "score = cohen_kappa_score(y_test, y_pred, weights='quadratic')\n",
    "print(f\"Train QWK: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d5a5938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.083508Z",
     "iopub.status.busy": "2024-05-28T11:04:24.082363Z",
     "iopub.status.idle": "2024-05-28T11:04:24.087983Z",
     "shell.execute_reply": "2024-05-28T11:04:24.086976Z"
    },
    "papermill": {
     "duration": 0.020948,
     "end_time": "2024-05-28T11:04:24.090163",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.069215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     param_grid = {\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "#     }\n",
    "\n",
    "#     xgb_regressor = xgb.XGBRegressor(\n",
    "#         objective=qwk_obj,\n",
    "#         random_state=42,\n",
    "#         **param_grid\n",
    "#     )\n",
    "    \n",
    "#     xgb_regressor.fit(X_train, y_train)\n",
    "#     y_val_pred = xgb_regressor.predict(X_test)\n",
    "#     y_val_pred_original = np.exp(y_val_pred)\n",
    "#     qwk_score = cohen_kappa_score(y_test.round(), y_val_pred_original.round(), weights=\"quadratic\")\n",
    "#     return np.mean(qwk_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57b76860",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.117417Z",
     "iopub.status.busy": "2024-05-28T11:04:24.116562Z",
     "iopub.status.idle": "2024-05-28T11:04:24.120999Z",
     "shell.execute_reply": "2024-05-28T11:04:24.120053Z"
    },
    "papermill": {
     "duration": 0.020379,
     "end_time": "2024-05-28T11:04:24.123023",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.102644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set up the Optuna study\n",
    "# study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "# study.optimize(objective, n_trials=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5741a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.149572Z",
     "iopub.status.busy": "2024-05-28T11:04:24.149188Z",
     "iopub.status.idle": "2024-05-28T11:04:24.153671Z",
     "shell.execute_reply": "2024-05-28T11:04:24.152665Z"
    },
    "papermill": {
     "duration": 0.020663,
     "end_time": "2024-05-28T11:04:24.156008",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.135345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Get the best hyperparameters\n",
    "# best_params = study.best_params\n",
    "# print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6efb4b0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.182629Z",
     "iopub.status.busy": "2024-05-28T11:04:24.181993Z",
     "iopub.status.idle": "2024-05-28T11:04:24.187151Z",
     "shell.execute_reply": "2024-05-28T11:04:24.186101Z"
    },
    "papermill": {
     "duration": 0.020848,
     "end_time": "2024-05-28T11:04:24.189535",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.168687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Train the final model with the best hyperparameters\n",
    "# xgb_regressor = xgb.XGBRegressor(\n",
    "#     objective=qwk_obj,\n",
    "#     random_state=42,\n",
    "#     **best_params\n",
    "# )\n",
    "\n",
    "# xgb_regressor.fit(\n",
    "#     X_train, y_train,\n",
    "#     early_stopping_rounds=10,\n",
    "#     eval_set=[(X_test, y_test)],\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# y_val_pred = xgb_regressor.predict(X_test)\n",
    "# y_val_pred_original = np.exp(y_val_pred)\n",
    "# qwk_score = cohen_kappa_score(y_test.round(), y_val_pred_original.round(), weights=\"quadratic\")\n",
    "# print(f\"Validation QWK Score: {qwk_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f64cbe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.215795Z",
     "iopub.status.busy": "2024-05-28T11:04:24.215404Z",
     "iopub.status.idle": "2024-05-28T11:04:24.313963Z",
     "shell.execute_reply": "2024-05-28T11:04:24.312804Z"
    },
    "papermill": {
     "duration": 0.114925,
     "end_time": "2024-05-28T11:04:24.316559",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.201634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>essay_length</th>\n",
       "      <th>sentences_count</th>\n",
       "      <th>paragraph_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>text_length_p</th>\n",
       "      <th>word_count_p</th>\n",
       "      <th>unique_word_count_p</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>...</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>text_standard</th>\n",
       "      <th>spache_readability</th>\n",
       "      <th>mcalpine_efg_time</th>\n",
       "      <th>syllablaw</th>\n",
       "      <th>readinle_count</th>\n",
       "      <th>lexicon_count</th>\n",
       "      <th>monosyllabcount</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>545</td>\n",
       "      <td>2677</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>248</td>\n",
       "      <td>2640</td>\n",
       "      <td>539</td>\n",
       "      <td>227</td>\n",
       "      <td>58.69</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.08</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>31.58</td>\n",
       "      <td>53.4</td>\n",
       "      <td>624</td>\n",
       "      <td>489</td>\n",
       "      <td>396</td>\n",
       "      <td>many people have car where they live the thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>371</td>\n",
       "      <td>1669</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>168</td>\n",
       "      <td>1663</td>\n",
       "      <td>371</td>\n",
       "      <td>152</td>\n",
       "      <td>87.55</td>\n",
       "      <td>...</td>\n",
       "      <td>6.714286</td>\n",
       "      <td>7.48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>19.57</td>\n",
       "      <td>25.7</td>\n",
       "      <td>398</td>\n",
       "      <td>332</td>\n",
       "      <td>275</td>\n",
       "      <td>i am a scientist at nasa that is discussing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>605</td>\n",
       "      <td>3077</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>243</td>\n",
       "      <td>3065</td>\n",
       "      <td>605</td>\n",
       "      <td>231</td>\n",
       "      <td>65.15</td>\n",
       "      <td>...</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>36.96</td>\n",
       "      <td>32.6</td>\n",
       "      <td>767</td>\n",
       "      <td>550</td>\n",
       "      <td>417</td>\n",
       "      <td>people always wish they had the same technolog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  word_count  essay_length  sentences_count  paragraph_count  \\\n",
       "0  000d118         545          2677               13                1   \n",
       "1  000fe60         371          1669               19                9   \n",
       "2  001ab80         605          3077               24                7   \n",
       "\n",
       "   unique_word_count  text_length_p  word_count_p  unique_word_count_p  \\\n",
       "0                248           2640           539                  227   \n",
       "1                168           1663           371                  152   \n",
       "2                243           3065           605                  231   \n",
       "\n",
       "   flesch_reading_ease  ...  linsear_write_formula  gunning_fog  \\\n",
       "0                58.69  ...              13.000000        17.08   \n",
       "1                87.55  ...               6.714286         7.48   \n",
       "2                65.15  ...              15.500000        11.49   \n",
       "\n",
       "   text_standard  spache_readability  mcalpine_efg_time  syllablaw  \\\n",
       "0           12.0                7.20              31.58       53.4   \n",
       "1            7.0                3.92              19.57       25.7   \n",
       "2           12.0                5.12              36.96       32.6   \n",
       "\n",
       "   readinle_count  lexicon_count  monosyllabcount  \\\n",
       "0             624            489              396   \n",
       "1             398            332              275   \n",
       "2             767            550              417   \n",
       "\n",
       "                                          clean_text  \n",
       "0  many people have car where they live the thing...  \n",
       "1  i am a scientist at nasa that is discussing th...  \n",
       "2  people always wish they had the same technolog...  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test = pd.read_csv('/kaggle/input/test-processed-csv/test_processed.csv')\n",
    "# df_test\n",
    "\n",
    "df_test = preprocess_df(df_test)\n",
    "df_test['clean_text'] = df_test['full_text'].apply(clean_text)\n",
    "df_test = df_test.drop('full_text', axis = 1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3fb6714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.343419Z",
     "iopub.status.busy": "2024-05-28T11:04:24.343084Z",
     "iopub.status.idle": "2024-05-28T11:04:24.347901Z",
     "shell.execute_reply": "2024-05-28T11:04:24.346816Z"
    },
    "papermill": {
     "duration": 0.02086,
     "end_time": "2024-05-28T11:04:24.350109",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.329249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Lấy mô hình tốt nhất\n",
    "# best_model = grids['XGBoost'].best_estimator_\n",
    "# best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fa2caad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.378183Z",
     "iopub.status.busy": "2024-05-28T11:04:24.377240Z",
     "iopub.status.idle": "2024-05-28T11:04:24.446273Z",
     "shell.execute_reply": "2024-05-28T11:04:24.445174Z"
    },
    "papermill": {
     "duration": 0.086369,
     "end_time": "2024-05-28T11:04:24.448857",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.362488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lưu lại cột essay_id để sử dụng sau này\n",
    "essay_ids = df_test['essay_id']\n",
    "\n",
    "# Xóa cột essay_id trước khi tiền xử lý\n",
    "X_test = df_test.drop('essay_id', axis=1)\n",
    "\n",
    "# Áp dụng pipeline đã huấn luyện để tiền xử lý dữ liệu test\n",
    "X_test_preprocessed = pipeline.transform(X_test)\n",
    "\n",
    "# Dự đoán điểm số trên dữ liệu test đã tiền xử lý\n",
    "y_pred_log = xgb_regressor.predict(X_test_preprocessed)\n",
    "# Chuyển đổi ngược từ log-transform\n",
    "y_pred = np.exp(y_pred_log)\n",
    "\n",
    "# Tạo dataframe chứa essay_id và dự đoán điểm số\n",
    "results = pd.DataFrame({'essay_id': essay_ids, 'score': y_pred})\n",
    "\n",
    "# Làm tròn điểm số\n",
    "results['score'] = round(results['score'])\n",
    "results['score'] = results['score'].astype(int)\n",
    "\n",
    "# Lưu kết quả ra file csv\n",
    "submission = results.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4928e139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T11:04:24.475606Z",
     "iopub.status.busy": "2024-05-28T11:04:24.475212Z",
     "iopub.status.idle": "2024-05-28T11:04:24.484888Z",
     "shell.execute_reply": "2024-05-28T11:04:24.483872Z"
    },
    "papermill": {
     "duration": 0.025495,
     "end_time": "2024-05-28T11:04:24.487157",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.461662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id  score\n",
       "0  000d118      2\n",
       "1  000fe60      3\n",
       "2  001ab80      4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323ec4b",
   "metadata": {
    "papermill": {
     "duration": 0.012244,
     "end_time": "2024-05-28T11:04:24.512309",
     "exception": false,
     "start_time": "2024-05-28T11:04:24.500065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8059942,
     "sourceId": 71485,
     "sourceType": "competition"
    },
    {
     "datasetId": 4956698,
     "sourceId": 8404441,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 615.078495,
   "end_time": "2024-05-28T11:04:26.954774",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-28T10:54:11.876279",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
