{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":8546791,"sourceType":"datasetVersion","datasetId":5106047}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Tải thủ công các thư viện ngoài","metadata":{}},{"cell_type":"code","source":"# Decomment this line of code if you already have those downloaded\n!pip install --no-index --no-deps /kaggle/input/aes-hcmus-whl/pyphen-0.15.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/aes-hcmus-whl/textstat-0.7.3-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:24.932885Z","iopub.execute_input":"2024-05-30T12:23:24.933816Z","iopub.status.idle":"2024-05-30T12:23:30.537406Z","shell.execute_reply.started":"2024-05-30T12:23:24.933776Z","shell.execute_reply":"2024-05-30T12:23:30.535914Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/aes-hcmus-whl/pyphen-0.15.0-py3-none-any.whl\nInstalling collected packages: pyphen\nSuccessfully installed pyphen-0.15.0\nProcessing /kaggle/input/aes-hcmus-whl/textstat-0.7.3-py3-none-any.whl\nInstalling collected packages: textstat\nSuccessfully installed textstat-0.7.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Import những thư viện cần thiết","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Basic libary\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport torch\nimport re\nimport optuna\nimport textstat\nfrom optuna.samplers import TPESampler\n# cmap = plt.cm.get_cmap('coolwarm')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Use for pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import cohen_kappa_score, f1_score, make_scorer\n\n# Use for training model\nfrom scipy.stats import randint\nfrom nltk.tokenize import word_tokenize\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier \nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import RandomizedSearchCV\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-05-30T12:23:30.540194Z","iopub.execute_input":"2024-05-30T12:23:30.540825Z","iopub.status.idle":"2024-05-30T12:23:36.459564Z","shell.execute_reply.started":"2024-05-30T12:23:30.540790Z","shell.execute_reply":"2024-05-30T12:23:36.458215Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/aes-hcmus-whl/pyproject_toml-0.0.10-py3-none-any.whl\n/kaggle/input/aes-hcmus-whl/textstat-0.7.3-py3-none-any.whl\n/kaggle/input/aes-hcmus-whl/pyphen-0.15.0-py3-none-any.whl\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Đọc file","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ndf_test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:36.460925Z","iopub.execute_input":"2024-05-30T12:23:36.461458Z","iopub.status.idle":"2024-05-30T12:23:37.319096Z","shell.execute_reply.started":"2024-05-30T12:23:36.461428Z","shell.execute_reply":"2024-05-30T12:23:37.318215Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess","metadata":{}},{"cell_type":"code","source":"essay_id_dropped = df_train['essay_id']\ndf_train = df_train.drop('essay_id', axis = 1)\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:37.322309Z","iopub.execute_input":"2024-05-30T12:23:37.323179Z","iopub.status.idle":"2024-05-30T12:23:37.359618Z","shell.execute_reply.started":"2024-05-30T12:23:37.323136Z","shell.execute_reply":"2024-05-30T12:23:37.357579Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   full_text  17307 non-null  object\n 1   score      17307 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 270.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:37.361026Z","iopub.execute_input":"2024-05-30T12:23:37.361429Z","iopub.status.idle":"2024-05-30T12:23:37.376767Z","shell.execute_reply.started":"2024-05-30T12:23:37.361393Z","shell.execute_reply":"2024-05-30T12:23:37.375734Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                           full_text  score\n0  Many people have car where they live. The thin...      3\n1  I am a scientist at NASA that is discussing th...      3\n2  People always wish they had the same technolog...      4\n3  We all heard about Venus, the planet without a...      4\n4  Dear, State Senator\\n\\nThis is a letter to arg...      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Many people have car where they live. The thin...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am a scientist at NASA that is discussing th...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>People always wish they had the same technolog...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We all heard about Venus, the planet without a...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\n\ndef dataPreprocessing(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = re.sub(r'\\xa0', '', x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:37.377974Z","iopub.execute_input":"2024-05-30T12:23:37.378311Z","iopub.status.idle":"2024-05-30T12:23:37.386142Z","shell.execute_reply.started":"2024-05-30T12:23:37.378283Z","shell.execute_reply":"2024-05-30T12:23:37.385241Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def textstat_features(text):\n    features = {}\n    features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n    features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n    features['smog_index'] = textstat.smog_index(text)\n    features['coleman_liau_index'] = textstat.coleman_liau_index(text)\n    features['automated_readability_index'] = textstat.automated_readability_index(text)\n    features['dale_chall_readability_score'] = textstat.dale_chall_readability_score(text)\n    features['difficult_words'] = textstat.difficult_words(text)\n    features['linsear_write_formula'] = textstat.linsear_write_formula(text)\n    features['gunning_fog'] = textstat.gunning_fog(text)\n    features['text_standard'] = textstat.text_standard(text, float_output=True)\n    features['spache_readability'] = textstat.spache_readability(text)\n    features['mcalpine_efg_time'] = textstat.reading_time(text)\n    features['syllablaw'] = textstat.mcalpine_eflaw(text)\n    features['readinle_count'] = textstat.syllable_count(text)\n    features['lexicon_count'] = textstat.lexicon_count(text)\n    features['monosyllabcount'] = textstat.monosyllabcount(text)\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:37.387453Z","iopub.execute_input":"2024-05-30T12:23:37.387823Z","iopub.status.idle":"2024-05-30T12:23:37.398622Z","shell.execute_reply.started":"2024-05-30T12:23:37.387795Z","shell.execute_reply":"2024-05-30T12:23:37.397531Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Number of words\nimport string\ndef preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n\n    # Length\n    df['essay_length'] = df['full_text'].str.len()\n\n    # Sentences count\n    # Adding a new column 'sentences_count' that counts the sentences in 'full_text'\n    df['sentences_count'] = df['full_text'].str.count(r'\\.')\n\n    # Paragraph count\n    # Adding a new column 'paragraph_count' that counts the paragraphs in 'full_text'\n    df['paragraph_count'] = df['full_text'].str.count(r'\\n') + 1\n    \n    df[\"text_tokens\"] = df[\"full_text\"].apply(lambda x: word_tokenize(x))\n    df[\"word_count\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n    df[\"unique_word_count\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n    df.drop(columns=[\"text_tokens\"], inplace=True)\n    \n    df[\"processed_text\"] = df[\"full_text\"].apply(lambda x: dataPreprocessing(x))\n    df[\"text_tokens\"] = df[\"processed_text\"].apply(lambda x: word_tokenize(x))\n    df[\"text_length_p\"] = df[\"processed_text\"].apply(lambda x: len(x))\n    df[\"word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n    df[\"unique_word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n    \n    # Applying textstat features\n    df['textstat_features'] = df['processed_text'].apply(textstat_features)\n    textstat_df = pd.DataFrame(df['textstat_features'].tolist())\n    df = pd.concat([df, textstat_df], axis=1)\n\n    df.drop(columns=[\"processed_text\", \"text_tokens\", \"textstat_features\"], inplace=True)\n    \n    return df\n\ndef clean_text(text):\n    text = re.sub(r'\\n', ' ', text)  # Loại bỏ xuống dòng\n    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ ký tự đặc biệt\n    text = re.sub(r'\\xa0', '', text)\n    text = text.lower()  # Chuyển thành chữ thường\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:37.399847Z","iopub.execute_input":"2024-05-30T12:23:37.400288Z","iopub.status.idle":"2024-05-30T12:23:37.416995Z","shell.execute_reply.started":"2024-05-30T12:23:37.400251Z","shell.execute_reply":"2024-05-30T12:23:37.415972Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_train = preprocess_df(df_train)\ndf_train['clean_text'] = df_train['full_text'].apply(clean_text)\ndf_train = df_train.drop('full_text', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:23:37.418339Z","iopub.execute_input":"2024-05-30T12:23:37.418696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cài đặt Pipeline","metadata":{}},{"cell_type":"markdown","source":"**Câu hỏi**: Pipeline là gì?\n\n> Pipeline là một cách để mã hóa và tự động hóa các công đoạn và quy trình làm việc cần thiết để tạo ra một mô hình học máy. Pipeline bao gồm nhiều bước tuần tự thực hiện mọi thứ từ trích xuất dữ liệu (data extraction) và tiền xử lý dữ liệu (preprocessing data) cho đến huấn luyện và triển khai mô hình.\n\n> Đối với các hệ thống sử dụng mô hình ML, thì quy trình pipeline là phần trung tâm của sản phẩm. Nó đóng gói toàn bộ các phương pháp xử lý dữ liệu tốt nhất để tạo ra một mô hình học máy phù hợp nhất cho một bộ dữ liệu cụ thể. Ngoài ra pipeline còn cho phép mô hình thực thi trên quy mô lớn. Một thiết kế pipeline end-to-end sẽ cho phép hệ thống của bạn cập nhật một cách thường xuyên các mô hình học máy một cách nhanh chóng.","metadata":{}},{"cell_type":"code","source":"# Decomment if want to use Pipeline again\nprint(\"Start running...\")\n# Define transformers for numerical and categorical columns\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n])\n\n# Add text vectorization step\ntext_vectorizer = TfidfVectorizer(\n    encoding='utf-8',\n    ngram_range=(1, 3),\n    strip_accents='unicode',\n    analyzer='word',\n    min_df=0.05,\n    max_df=0.95,\n    sublinear_tf=True\n)\ntext_transformer = Pipeline(steps=[\n    ('vectorizer', text_vectorizer)\n])\n\n# Update categorical and numerical columns\nnumerical_columns = df_train.select_dtypes(include=['int64', 'float64']).columns\ncategorical_columns = df_train.select_dtypes('object').columns\n\n# Remove target variable from numerical columns\nnumerical_columns = numerical_columns.drop('score')\n\n# Combine transformers using ColumnTransformer\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_columns),\n        ('cat', categorical_transformer, categorical_columns),\n        ('text', text_transformer, 'clean_text')  # Include the 'clean_text' column\n    ],remainder = 'passthrough')\n\n# Create a pipeline with the preprocessor\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor)])\n\n# Apply the pipeline to your dataset\nX = df_train.drop('score', axis=1)\ny = np.log(df_train['score'])\nX_preprocessed = pipeline.fit_transform(X)\nprint(\"This Pipeline is done\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Chia thành các tập train và tập test cho mô hình","metadata":{}},{"cell_type":"code","source":"# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, \n                                                    test_size=0.2, random_state=42)\n\nprint(\"Train set shape: \", X_train.shape, \" ; \", y_train.shape)\nprint(\"Test set shape: \",X_test.shape, \" ; \" ,y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cài đặt chấm điểm dựa theo cách chấm điểm của cuộc thi\n\n> Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement).\n\nCác bài nộp được tính điểm dựa trên kappa có trọng số bậc hai, thước đo sự phù hợp giữa hai kết quả. Số liệu này thường thay đổi từ 0 (thỏa thuận ngẫu nhiên) đến 1 (thỏa thuận hoàn chỉnh).","metadata":{}},{"cell_type":"code","source":"# # idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\ndef quadratic_weighted_kappa(y_test_log, y_pred_log):\n    y_pred = np.exp(y_pred_log)\n    y_pred = y_pred.clip(1, 6).round()\n    \n    y_test_exp = np.exp(y_test_log)\n\n    # Calculate the Cohen's kappa score\n    score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n    return score\n\n# metric and objective based on public notebooks\ndef qwk_obj(y_true, y_pred):\n    labels = y_true + a\n    preds = y_pred + a\n    preds = preds.clip(1, 6)\n    f = 1/2*np.sum((preds-labels)**2)\n    g = 1/2*np.sum((preds-a)**2+b)\n    df = preds - labels\n    dg = preds - a\n    grad = (df/g - f*dg/g**2)*len(labels)\n    hess = np.ones(len(labels))\n    return grad, hess\n\na = 2.998\nb = 1.092","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Huấn luyện mô hình","metadata":{}},{"cell_type":"code","source":"print(\"Start running...\")\n\nxgb_callbacks = [\n    xgb.callback.EvaluationMonitor(period=25),\n    xgb.callback.EarlyStopping(75, metric_name=\"QWK\", maximize=True, save_best=True)\n]\n\nxgb_regressor = xgb.XGBRegressor(\n    objective=qwk_obj,  # Use custom QWK objective function\n    n_estimators= 207,\n    learning_rate= 0.10704240620854825,\n    min_split_loss = 1,\n    max_depth= 6,\n    subsample= 0.6389081081835488,\n    max_bin = 337,\n    random_state=42,\n    num_leaves = 10,\n    extra_trees=True,\n    class_weight='balanced',\n    tree_method=\"hist\"\n)\n\n# Train the model\nxgb_regressor.fit(X_train, y_train)\n#                 eval_set=[(X_train, y_train), (X_test, y_test)],\n#                 eval_metric=quadratic_weighted_kappa,\n#                 callbacks=xgb_callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dự đoán kết quả bằng mô hình vừa huấn luyện","metadata":{}},{"cell_type":"code","source":"# Make predictions on the validation set\ny_pred = xgb_regressor.predict(X_test)\n\n# Calculate the Cohen's kappa score\nscore = quadratic_weighted_kappa(y_test, y_pred)\nprint(f\"Train QWK: {score:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Optuna\n\n> An open source hyperparameter optimization framework to automate hyperparameter search","metadata":{}},{"cell_type":"markdown","source":" **Câu hỏi**: Khó khăn gặp phải khi phải điều chỉnh tham số thủ công?\n \n - Việc chọn siêu tham số khi thực hiện training mô hình dường như đều dựa vào cảm tính và kinh nghiệm của người lập trình. Và điều nay không phải lúc nào cũng có thể làm cho mô hình đạt hiệu suất, kết quả tốt nhất . Còn đối với những lập trình viên chưa có kinh nghiệm lựa chọn siêu tham số thì đây thực sự là một thử thách khi đòi hỏi phải có kiến thức và kinh nghiệm nhất định.","metadata":{}},{"cell_type":"markdown","source":" **Câu hỏi**: Optuna là gì ?\n \n - Optuna là 1 framwork hỗ trợ việc tự động điều chỉnh tham số mô hình để mô hình có thể đạt được hiệu năng tốt nhất ứng. Do đó giúp giảm bớt thời gian và công sức khi chúng ta không cần phải điều chỉnh các siêu tham số một cách thủ công nữa. Từ đó giúp tăng năng suất công việc.","metadata":{}},{"cell_type":"markdown","source":"#### Định nghĩa objective function\n\n**Trial object definition**: \n\n> Trial là một đối tượng thể hiện của một class được thực thi trong Optuna.Nó được sử dụng để định nghĩa các siêu tham số được tối ưu. Giá trị được lấy trong phạm vi được định nghĩa, thông tin của các tham số được tìm kiếm trong quá khứ vẫn được giữ lại và giá trị mới sẽ dựa trên những thông tin đó. \n\nHay dễ hiểu hơn là Optuna sẽ duyệt qua các tham số được cài đặt thử nghiệm và chọn tập hợp siêu tham số có kết quả tốt nhất là tham số sử dụng cho mô hình cuối cùng.","metadata":{}},{"cell_type":"code","source":"# def objective(trial):\n#     param_grid = {\n#         'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n#         'min_split_loss': trial.suggest_int('min_split_loss', 0, 9),\n#         'max_depth': trial.suggest_int('max_depth', 6, 12),\n#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n#         'max_bin': trial.suggest_int('max_bin', 256, 512)\n#     }\n\n#     xgb_regressor = xgb.XGBRegressor(\n#         objective=qwk_obj,\n#         random_state=42,\n#         tree_method=\"hist\",\n#         **param_grid\n#     )\n    \n#     xgb_regressor.fit(X_train, y_train)\n    \n#     y_pred_log = xgb_regressor.predict(X_test)\n#     y_pred = np.exp(y_pred_log)\n#     # y_pred = y_pred + a\n#     y_pred = y_pred.clip(1, 6).round()\n#     y_test_exp = np.exp(y_test)\n\n#     # Calculate the Cohen's kappa score\n#     score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n#     return np.mean(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Định nghĩa study object**: Để tìm kiếm siêu tham số, bạn cần khởi tạo một đối tượng là study \n\n> Đối tượng này lưu kết quả tối ưu của bạn.\n\n**Sau đó, sử dụng phương thức optimize**:\n\n- Trong đó, tham số thứ 1 là hàm Objective \n- Tham số thứ 2 là số lượng thử nghiệm. \n\n> Quá trình tối ưu này được thực hiện trong đối tượng Study và sẽ thực hiện tìm giá trị cực tiểu của các tham số trong hàm Objective bằng phương pháp tối ưu hóa. ","metadata":{}},{"cell_type":"code","source":"# # Set up the Optuna study\n# study = optuna.create_study(direction='maximize', sampler=TPESampler())\n# study.optimize(objective, n_trials=40, n_jobs=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Khi kết thúc quá trình trên, giá trị tối ưu sẽ được lưu lại và bạn có thể xem nó bằng câu lệnh sau:","metadata":{}},{"cell_type":"code","source":"# # Get the best hyperparameters\n# best_params = study.best_params\n# print(\"Best Hyperparameters:\", best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Thực hiện áp dụng các siêu tham số mà framework Optuna đã huấn luyện và chọn lọc","metadata":{}},{"cell_type":"code","source":"# # Train the final model with the best hyperparameters\n# xgb_regressor = xgb.XGBRegressor(\n#     objective=qwk_obj,\n#     random_state=42,\n#     **best_params\n# )\n\n# xgb_regressor.fit(\n#     X_train, y_train,\n#     early_stopping_rounds=10,\n#     eval_set=[(X_test, y_test)],\n#     verbose=True\n# )\n\n# y_pred_log = xgb_regressor.predict(X_test)\n# y_pred = np.exp(y_pred_log)\n# # y_pred = y_pred + a\n# y_pred = y_pred.clip(1, 6).round()\n# y_test_exp = np.exp(y_test)\n\n# # Calculate the Cohen's kappa score\n# score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n# print(f\"Train QWK: {score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Thực hiện áp dụng Model đã huấn luyện vào file test.csv","metadata":{}},{"cell_type":"code","source":"# df_test = pd.read_csv('/kaggle/input/test-processed-csv/test_processed.csv')\n# df_test\n\ndf_test = preprocess_df(df_test)\ndf_test['clean_text'] = df_test['full_text'].apply(clean_text)\ndf_test = df_test.drop('full_text', axis = 1)\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xuất kết quả ra file submission và nộp bài","metadata":{}},{"cell_type":"code","source":"# Lưu lại cột essay_id để sử dụng sau này\nessay_ids = df_test['essay_id']\n\n# Xóa cột essay_id trước khi tiền xử lý\nX_test = df_test.drop('essay_id', axis=1)\n\n# Áp dụng pipeline đã huấn luyện để tiền xử lý dữ liệu test\nX_test_preprocessed = pipeline.transform(X_test)\n\n# Dự đoán điểm số trên dữ liệu test đã tiền xử lý\ny_pred_log = xgb_regressor.predict(X_test_preprocessed)\n\n# Chuyển đổi ngược từ log-transform\ny_pred = np.exp(y_pred_log)\n\n# Tạo dataframe chứa essay_id và dự đoán điểm số\nresults = pd.DataFrame({'essay_id': essay_ids, 'score': y_pred})\n\n# Làm tròn điểm số\nresults['score'] = round(results['score'])\nresults['score'] = results['score'].astype(int)\n\n# Lưu kết quả ra file csv\nsubmission = results.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}