{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport torch\nimport re\ncmap = plt.cm.get_cmap('coolwarm')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Use for pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\n\nfrom nltk.tokenize import word_tokenize\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier \nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T08:19:05.544768Z","iopub.execute_input":"2024-05-22T08:19:05.545164Z","iopub.status.idle":"2024-05-22T08:19:09.301446Z","shell.execute_reply.started":"2024-05-22T08:19:05.545132Z","shell.execute_reply":"2024-05-22T08:19:09.300219Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_236/1917670379.py:13: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  cmap = plt.cm.get_cmap('coolwarm')\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ndf_test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:53:50.538093Z","iopub.execute_input":"2024-05-22T08:53:50.538582Z","iopub.status.idle":"2024-05-22T08:53:50.989179Z","shell.execute_reply.started":"2024-05-22T08:53:50.538547Z","shell.execute_reply":"2024-05-22T08:53:50.987591Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"essay_id_dropped = df_train['essay_id']\ndf_train = df_train.drop('essay_id', axis = 1)\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:53:51.223873Z","iopub.execute_input":"2024-05-22T08:53:51.224307Z","iopub.status.idle":"2024-05-22T08:53:51.247641Z","shell.execute_reply.started":"2024-05-22T08:53:51.224259Z","shell.execute_reply":"2024-05-22T08:53:51.246131Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   full_text  17307 non-null  object\n 1   score      17307 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 270.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:53:51.868310Z","iopub.execute_input":"2024-05-22T08:53:51.868779Z","iopub.status.idle":"2024-05-22T08:53:51.879717Z","shell.execute_reply.started":"2024-05-22T08:53:51.868740Z","shell.execute_reply":"2024-05-22T08:53:51.878655Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                           full_text  score\n0  Many people have car where they live. The thin...      3\n1  I am a scientist at NASA that is discussing th...      3\n2  People always wish they had the same technolog...      4\n3  We all heard about Venus, the planet without a...      4\n4  Dear, State Senator\\n\\nThis is a letter to arg...      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Many people have car where they live. The thin...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am a scientist at NASA that is discussing th...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>People always wish they had the same technolog...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We all heard about Venus, the planet without a...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\n\n\ncList = {\n    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\",\n    \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n    \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n    # \"he'd\": \"he would\",  ## --> he had or he would\n    \"he'd've\": \"he would have\",\"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\", \n    \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\n    # \"I'd\": \"I would\",   ## --> I had or I would\n    \"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\"isn't\": \"is not\",\n    # \"it'd\": \"it had\",   ## --> It had or It would\n    \"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\"it's\": \"it is\",\n    \"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n    \"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n    \"needn't\": \"need not\",\"needn't've\": \"need not have\",\n    \"o'clock\": \"of the clock\",\n    \"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\n    \"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\n    # \"she'd\": \"she would\",   ## --> It had or It would\n    \"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n    \"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\n    \"so've\": \"so have\",\"so's\": \"so is\",\n    # \"that'd\": \"that would\",\n    \"that'd've\": \"that would have\",\"that's\": \"that is\",\n    # \"there'd\": \"there had\",\n    \"there'd've\": \"there would have\",\"there's\": \"there is\",\n    # \"they'd\": \"they would\",\n    \"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\n    \"to've\": \"to have\",\"wasn't\": \"was not\",\"weren't\": \"were not\",\n    # \"we'd\": \"we had\",\n    \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n    \"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\n    \"when's\": \"when is\",\"when've\": \"when have\",\n    \"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\n    \"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\"why've\": \"why have\",\n    \"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n    \"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\n    \"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\n    \"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\n    \"you're\": \"you are\",  \"you've\": \"you have\"\n}\nc_re = re.compile('(%s)' % '|'.join(cList.keys()))\n\ndef expandContractions(text):\n    def replace(match):\n        return cList[match.group(0)]\n    return c_re.sub(replace, text)\n\ndef remove_punctuation(text):\n    \"\"\"\n    Remove all punctuation from the input text.\n    \n    Args:\n    - text (str): The input text.\n    \n    Returns:\n    - str: The text with punctuation removed.\n    \"\"\"\n    # string.punctuation\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\ndef dataPreprocessing(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x\n\ndef dataPreprocessing_w_contract(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    x = expandContractions(x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x\n\ndef dataPreprocessing_w_punct_remove(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = remove_punctuation(x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x\n\ndef dataPreprocessing_w_contract_punct_remove(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    x = expandContractions(x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = remove_punctuation(x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:53:52.822287Z","iopub.execute_input":"2024-05-22T08:53:52.823095Z","iopub.status.idle":"2024-05-22T08:53:52.855729Z","shell.execute_reply.started":"2024-05-22T08:53:52.823051Z","shell.execute_reply":"2024-05-22T08:53:52.854150Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Number of words\nimport string\ndef preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n\n    # Length\n    df['essay_length'] = df['full_text'].str.len()\n\n    # Sentences count\n    # Adding a new column 'sentences_count' that counts the sentences in 'full_text'\n    df['sentences_count'] = df['full_text'].str.count(r'\\.')\n\n    # Paragraph count\n    # Adding a new column 'paragraph_count' that counts the paragraphs in 'full_text'\n    df['paragraph_count'] = df['full_text'].str.count(r'\\n') + 1\n    \n    return df\n\ndef clean_text(text):\n    text = re.sub(r'\\n', ' ', text)  # Loại bỏ xuống dòng\n    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ ký tự đặc biệt\n    text = text.lower()  # Chuyển thành chữ thường\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:53:52.859098Z","iopub.execute_input":"2024-05-22T08:53:52.859592Z","iopub.status.idle":"2024-05-22T08:53:52.873053Z","shell.execute_reply.started":"2024-05-22T08:53:52.859552Z","shell.execute_reply":"2024-05-22T08:53:52.871576Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df_train = preprocess_df(df_train)\n#df_train['clean_text'] = df_train['full_text'].apply(clean_text)\n#df_train = df_train.drop('full_text', axis = 1)\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:53:52.874926Z","iopub.execute_input":"2024-05-22T08:53:52.875298Z","iopub.status.idle":"2024-05-22T08:53:53.521838Z","shell.execute_reply.started":"2024-05-22T08:53:52.875266Z","shell.execute_reply":"2024-05-22T08:53:53.520554Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                           full_text  score  word_count  \\\n0  Many people have car where they live. The thin...      3         498   \n1  I am a scientist at NASA that is discussing th...      3         332   \n2  People always wish they had the same technolog...      4         550   \n3  We all heard about Venus, the planet without a...      4         451   \n4  Dear, State Senator\\n\\nThis is a letter to arg...      3         373   \n\n   essay_length  sentences_count  paragraph_count  \n0          2677               13                1  \n1          1669               19                9  \n2          3077               24                7  \n3          2701               23                9  \n4          2208               15               11  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>score</th>\n      <th>word_count</th>\n      <th>essay_length</th>\n      <th>sentences_count</th>\n      <th>paragraph_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Many people have car where they live. The thin...</td>\n      <td>3</td>\n      <td>498</td>\n      <td>2677</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am a scientist at NASA that is discussing th...</td>\n      <td>3</td>\n      <td>332</td>\n      <td>1669</td>\n      <td>19</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>People always wish they had the same technolog...</td>\n      <td>4</td>\n      <td>550</td>\n      <td>3077</td>\n      <td>24</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We all heard about Venus, the planet without a...</td>\n      <td>4</td>\n      <td>451</td>\n      <td>2701</td>\n      <td>23</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n      <td>3</td>\n      <td>373</td>\n      <td>2208</td>\n      <td>15</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:19:27.880001Z","iopub.execute_input":"2024-05-22T08:19:27.880424Z","iopub.status.idle":"2024-05-22T08:19:27.901269Z","shell.execute_reply.started":"2024-05-22T08:19:27.880393Z","shell.execute_reply":"2024-05-22T08:19:27.897443Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 6 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   full_text        17307 non-null  object\n 1   score            17307 non-null  int64 \n 2   word_count       17307 non-null  int64 \n 3   essay_length     17307 non-null  int64 \n 4   sentences_count  17307 non-null  int64 \n 5   paragraph_count  17307 non-null  int64 \ndtypes: int64(5), object(1)\nmemory usage: 811.4+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# rows_to_drop = df_train.query('sentences_count > 60 | (sentences_count > 50 & score == 1)').index\n\n# # Xóa các dòng có index tương ứng\n\n# df_train.drop(rows_to_drop, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rows_to_drop = df_train.query('paragraph_count > 80 | (paragraph_count > 55 & score == 1 ) | (paragraph_count >60 & score == 2 ) | (paragraph_count > 30  & score == 5) | (paragraph_count > 25  & score == 6)').index\n\n# # Xóa các dòng có index tương ứng\n\n# df_train.drop(rows_to_drop, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decomment if want to use Pipeline again\n\n# # Define transformers for numerical and categorical columns\n# numerical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='mean')),\n#     ('scaler', StandardScaler())\n# ])\n# categorical_transformer = Pipeline(steps=[\n#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n#     ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n# ])\n\n# # Update categorical and numerical columns\n# numerical_columns = df_train.select_dtypes('int64').columns\n# categorical_columns = df_train.select_dtypes('object').columns\n\n# # Remove target variable from numerical columns\n# numerical_columns = numerical_columns.drop('score')\n\n# # Combine transformers using ColumnTransformer\n\n# preprocessor = ColumnTransformer(\n#     transformers=[\n#         ('num', numerical_transformer, numerical_columns),\n#         ('cat', categorical_transformer, categorical_columns)\n#     ],remainder = 'passthrough')\n\n# # Create a pipeline with the preprocessor\n# pipeline = Pipeline(steps=[\n#     ('preprocessor', preprocessor)])\n\n# # Apply the pipeline to your dataset\n# X = df_train.drop('score', axis=1)\n# y = np.log(df_train['score']) #normalize dependent variable \n# X_preprocessed = pipeline.fit_transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(\n    encoding='utf-8',\n    ngram_range=(1, 3),\n    strip_accents='unicode',\n    analyzer='word',\n    min_df=0.05,\n    max_df=0.95,\n    sublinear_tf=True\n)\n\ntrain_vectorized = pd.DataFrame(\n    vectorizer.fit_transform(df_train['full_text']).toarray(),\n    columns=[f\"tfidf_{str(f)}\" for f in vectorizer.get_feature_names_out()],\n)\n\ntrain_vectorized.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:53:59.485728Z","iopub.execute_input":"2024-05-22T08:53:59.486170Z","iopub.status.idle":"2024-05-22T08:54:35.513736Z","shell.execute_reply.started":"2024-05-22T08:53:59.486132Z","shell.execute_reply":"2024-05-22T08:54:35.512497Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"   tfidf_2001  tfidf_25  tfidf_800  tfidf_800 degrees  tfidf_90  \\\n0         0.0       0.0   0.000000           0.000000       0.0   \n1         0.0       0.0   0.000000           0.000000       0.0   \n2         0.0       0.0   0.000000           0.000000       0.0   \n3         0.0       0.0   0.103766           0.107932       0.0   \n4         0.0       0.0   0.000000           0.000000       0.0   \n\n   tfidf_90 times  tfidf_97  tfidf_able  tfidf_able to  tfidf_about  ...  \\\n0             0.0  0.000000    0.000000       0.000000     0.030514  ...   \n1             0.0  0.000000    0.000000       0.000000     0.056296  ...   \n2             0.0  0.000000    0.037994       0.038167     0.045009  ...   \n3             0.0  0.065964    0.000000       0.000000     0.058216  ...   \n4             0.0  0.000000    0.000000       0.000000     0.032475  ...   \n\n   tfidf_you get  tfidf_you have  tfidf_you have to  tfidf_you should  \\\n0            0.0             0.0                0.0          0.000000   \n1            0.0             0.0                0.0          0.127747   \n2            0.0             0.0                0.0          0.000000   \n3            0.0             0.0                0.0          0.000000   \n4            0.0             0.0                0.0          0.000000   \n\n   tfidf_you think  tfidf_you to  tfidf_you want  tfidf_you will  \\\n0         0.000000           0.0             0.0             0.0   \n1         0.132225           0.0             0.0             0.0   \n2         0.000000           0.0             0.0             0.0   \n3         0.000000           0.0             0.0             0.0   \n4         0.000000           0.0             0.0             0.0   \n\n   tfidf_you would  tfidf_your  \n0              0.0    0.039513  \n1              0.0    0.000000  \n2              0.0    0.000000  \n3              0.0    0.000000  \n4              0.0    0.000000  \n\n[5 rows x 1203 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tfidf_2001</th>\n      <th>tfidf_25</th>\n      <th>tfidf_800</th>\n      <th>tfidf_800 degrees</th>\n      <th>tfidf_90</th>\n      <th>tfidf_90 times</th>\n      <th>tfidf_97</th>\n      <th>tfidf_able</th>\n      <th>tfidf_able to</th>\n      <th>tfidf_about</th>\n      <th>...</th>\n      <th>tfidf_you get</th>\n      <th>tfidf_you have</th>\n      <th>tfidf_you have to</th>\n      <th>tfidf_you should</th>\n      <th>tfidf_you think</th>\n      <th>tfidf_you to</th>\n      <th>tfidf_you want</th>\n      <th>tfidf_you will</th>\n      <th>tfidf_you would</th>\n      <th>tfidf_your</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.030514</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.039513</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.056296</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.127747</td>\n      <td>0.132225</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.037994</td>\n      <td>0.038167</td>\n      <td>0.045009</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.103766</td>\n      <td>0.107932</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.065964</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.058216</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.032475</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1203 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = pd.concat([df_train, train_vectorized], axis=1).drop(columns=[\"full_text\", \"score\"], axis=1)\ny = df_train[\"score\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:55:26.269951Z","iopub.execute_input":"2024-05-22T08:55:26.270385Z","iopub.status.idle":"2024-05-22T08:55:26.871454Z","shell.execute_reply.started":"2024-05-22T08:55:26.270353Z","shell.execute_reply":"2024-05-22T08:55:26.870214Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T08:55:27.891465Z","iopub.execute_input":"2024-05-22T08:55:27.892354Z","iopub.status.idle":"2024-05-22T08:55:28.014111Z","shell.execute_reply.started":"2024-05-22T08:55:27.892307Z","shell.execute_reply":"2024-05-22T08:55:28.012884Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Define the models\nmodels = {\n    'XGBoost': XGBRegressor(random_state=42)\n}\n\n# Define the hyperparameter grids for each model\nparam_grids = {\n    'XGBoost': {\n        'n_estimators': [1024],\n        'learning_rate': [0.1],\n        'max_depth': [8],\n        'subsample': [0.5],\n#         'colsample_bytree': [0.5]\n    }\n}\n\n# 3-fold cross-validation\ncv = KFold(n_splits=3, shuffle=True, random_state=42)\n\n# Train and tune the models\ngrids = {}\nfor model_name, model in models.items():\n    grids[model_name] = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n    grids[model_name].fit(X_train, y_train)\n    best_params = grids[model_name].best_params_\n    best_score = np.sqrt(-1 * grids[model_name].best_score_)\n    \n    print(f'Best parameters for {model_name}: {best_params}')\n    print(f'Best RMSE for {model_name}: {best_score}\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_test = pd.read_csv('/kaggle/input/test-processed-csv/test_processed.csv')\n# df_test\n\ndf_test = preprocess_df(df_test)\ndf_test['clean_text'] = df_test['full_text'].apply(clean_text)\ndf_test = df_test.drop('full_text', axis = 1)\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the pipeline to dataset\nX_test_preprocessed = pipeline.transform(df_test)\n\n# Lấy mô hình tốt nhất\nbest_model = grids['XGBoost'].best_estimator_\nbest_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lưu lại cột essay_id để sử dụng sau này\nessay_ids = df_test['essay_id']\n\n# Xóa cột essay_id trước khi tiền xử lý\nX_test = df_test.drop('essay_id', axis=1)\n\n# Áp dụng pipeline đã huấn luyện để tiền xử lý dữ liệu test\nX_test_preprocessed = pipeline.transform(X_test)\n\n# Dự đoán điểm số trên dữ liệu test đã tiền xử lý\ny_pred_log = grids['XGBoost'].predict(X_test_preprocessed)\n\n# Chuyển đổi ngược từ log-transform\ny_pred = np.exp(y_pred_log)\n\n# Tạo dataframe chứa essay_id và dự đoán điểm số\nresults = pd.DataFrame({'essay_id': essay_ids, 'score': y_pred})\n\n# Làm tròn điểm số\nresults['score'] = round(results['score'])\nresults['score'] = results['score'].astype(int)\n\n# Lưu kết quả ra file csv\nsubmission = results.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}