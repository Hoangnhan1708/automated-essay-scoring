{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":8561129,"sourceType":"datasetVersion","datasetId":5106047}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Tải thủ công các thư viện ngoài","metadata":{}},{"cell_type":"code","source":"# Comment this line of code if you already have those downloaded\n!pip install --no-index --no-deps /kaggle/input/aes-hcmus-whl/pyphen-0.15.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/aes-hcmus-whl/textstat-0.7.3-py3-none-any.whl\n# !pip install --no-index --no-deps /kaggle/input/aes-hcmus-whl/pyspellchecker-0.8.1-py3-none-any.whl\nprint(\"\\nDone installing\")","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:19:52.505055Z","iopub.execute_input":"2024-06-05T08:19:52.505590Z","iopub.status.idle":"2024-06-05T08:19:58.982043Z","shell.execute_reply.started":"2024-06-05T08:19:52.505552Z","shell.execute_reply":"2024-06-05T08:19:58.980294Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/aes-hcmus-whl/pyphen-0.15.0-py3-none-any.whl\npyphen is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nProcessing /kaggle/input/aes-hcmus-whl/textstat-0.7.3-py3-none-any.whl\ntextstat is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n\nDone installing\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Import những thư viện cần thiết","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Basic libary\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport torch\nimport re\nimport optuna\nimport textstat\nfrom optuna.samplers import TPESampler\n# cmap = plt.cm.get_cmap('coolwarm')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Use for pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\nfrom sklearn.metrics import cohen_kappa_score, f1_score, make_scorer\n\n# Use for training model\nfrom scipy.stats import randint\nfrom nltk.tokenize import word_tokenize\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier \nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score, StratifiedKFold\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import RandomizedSearchCV\nimport lightgbm as lgb\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-06-05T08:19:58.985450Z","iopub.execute_input":"2024-06-05T08:19:58.986032Z","iopub.status.idle":"2024-06-05T08:20:09.864161Z","shell.execute_reply.started":"2024-06-05T08:19:58.985978Z","shell.execute_reply":"2024-06-05T08:20:09.862882Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\n/kaggle/input/aes-hcmus-whl/pyproject_toml-0.0.10-py3-none-any.whl\n/kaggle/input/aes-hcmus-whl/textstat-0.7.3-py3-none-any.whl\n/kaggle/input/aes-hcmus-whl/pyspellchecker-0.8.1-py3-none-any.whl\n/kaggle/input/aes-hcmus-whl/pyphen-0.15.0-py3-none-any.whl\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Đọc file","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:20:09.865663Z","iopub.execute_input":"2024-06-05T08:20:09.866270Z","iopub.status.idle":"2024-06-05T08:20:10.833175Z","shell.execute_reply.started":"2024-06-05T08:20:09.866237Z","shell.execute_reply":"2024-06-05T08:20:10.831817Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess","metadata":{}},{"cell_type":"code","source":"essay_id_dropped = df_train['essay_id']\ndf_train = df_train.drop('essay_id', axis = 1)\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:20:10.836138Z","iopub.execute_input":"2024-06-05T08:20:10.836563Z","iopub.status.idle":"2024-06-05T08:20:10.881800Z","shell.execute_reply.started":"2024-06-05T08:20:10.836528Z","shell.execute_reply":"2024-06-05T08:20:10.880381Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   full_text  17307 non-null  object\n 1   score      17307 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 270.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:20:10.883331Z","iopub.execute_input":"2024-06-05T08:20:10.883878Z","iopub.status.idle":"2024-06-05T08:20:10.902372Z","shell.execute_reply.started":"2024-06-05T08:20:10.883753Z","shell.execute_reply":"2024-06-05T08:20:10.901093Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                           full_text  score\n0  Many people have car where they live. The thin...      3\n1  I am a scientist at NASA that is discussing th...      3\n2  People always wish they had the same technolog...      4\n3  We all heard about Venus, the planet without a...      4\n4  Dear, State Senator\\n\\nThis is a letter to arg...      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Many people have car where they live. The thin...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am a scientist at NASA that is discussing th...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>People always wish they had the same technolog...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We all heard about Venus, the planet without a...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\n\ndef dataPreprocessing(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = re.sub(r'\\xa0', '', x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:20:10.903915Z","iopub.execute_input":"2024-06-05T08:20:10.904274Z","iopub.status.idle":"2024-06-05T08:20:10.915244Z","shell.execute_reply.started":"2024-06-05T08:20:10.904243Z","shell.execute_reply":"2024-06-05T08:20:10.913780Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def textstat_features(text):\n    features = {}\n    features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n    features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n    features['smog_index'] = textstat.smog_index(text)\n    features['coleman_liau_index'] = textstat.coleman_liau_index(text)\n    features['automated_readability_index'] = textstat.automated_readability_index(text)\n    features['dale_chall_readability_score'] = textstat.dale_chall_readability_score(text)\n    features['difficult_words'] = textstat.difficult_words(text)\n    features['linsear_write_formula'] = textstat.linsear_write_formula(text)\n    features['gunning_fog'] = textstat.gunning_fog(text)\n    features['text_standard'] = textstat.text_standard(text, float_output=True)\n    features['spache_readability'] = textstat.spache_readability(text)\n    features['mcalpine_efg_time'] = textstat.reading_time(text)\n    features['syllablaw'] = textstat.mcalpine_eflaw(text)\n    features['readinle_count'] = textstat.syllable_count(text)\n    features['lexicon_count'] = textstat.lexicon_count(text)\n    features['monosyllabcount'] = textstat.monosyllabcount(text)\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:20:10.916966Z","iopub.execute_input":"2024-06-05T08:20:10.917391Z","iopub.status.idle":"2024-06-05T08:20:10.931279Z","shell.execute_reply.started":"2024-06-05T08:20:10.917355Z","shell.execute_reply":"2024-06-05T08:20:10.929611Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Number of words\nimport string\ndef preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n\n    # Length\n    df['essay_length'] = df['full_text'].str.len()\n\n    # Sentences count\n    # Adding a new column 'sentences_count' that counts the sentences in 'full_text'\n    df['sentences_count'] = df['full_text'].str.count(r'\\.')\n\n    # Paragraph count\n    # Adding a new column 'paragraph_count' that counts the paragraphs in 'full_text'\n    df['paragraph_count'] = df['full_text'].str.count(r'\\n') + 1\n    \n    df[\"text_tokens\"] = df[\"full_text\"].apply(lambda x: word_tokenize(x))\n    df[\"word_count\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n    df[\"unique_word_count\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n    df.drop(columns=[\"text_tokens\"], inplace=True)\n    \n    df[\"processed_text\"] = df[\"full_text\"].apply(lambda x: dataPreprocessing(x))\n    df[\"text_tokens\"] = df[\"processed_text\"].apply(lambda x: word_tokenize(x))\n    df[\"text_length_p\"] = df[\"processed_text\"].apply(lambda x: len(x))\n    df[\"word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n    df[\"unique_word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n    \n    # Applying textstat features\n    df['textstat_features'] = df['processed_text'].apply(textstat_features)\n    textstat_df = pd.DataFrame(df['textstat_features'].tolist())\n    df = pd.concat([df, textstat_df], axis=1)\n\n    df.drop(columns=[\"processed_text\", \"text_tokens\", \"textstat_features\"], inplace=True)\n    \n    return df\n\ndef clean_text(text):\n    text = re.sub(r'\\n', ' ', text)  # Loại bỏ xuống dòng\n    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ ký tự đặc biệt\n    text = re.sub(r'\\xa0', '', text)\n    text = text.lower()  # Chuyển thành chữ thường\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:20:10.933234Z","iopub.execute_input":"2024-06-05T08:20:10.933687Z","iopub.status.idle":"2024-06-05T08:20:10.950650Z","shell.execute_reply.started":"2024-06-05T08:20:10.933638Z","shell.execute_reply":"2024-06-05T08:20:10.949325Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_train = preprocess_df(df_train)\ndf_train['clean_text'] = df_train['full_text'].apply(clean_text)\ndf_train = df_train.drop('full_text', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:20:10.952880Z","iopub.execute_input":"2024-06-05T08:20:10.953321Z","iopub.status.idle":"2024-06-05T08:26:07.977482Z","shell.execute_reply.started":"2024-06-05T08:20:10.953285Z","shell.execute_reply":"2024-06-05T08:26:07.974917Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:26:07.984189Z","iopub.execute_input":"2024-06-05T08:26:07.984636Z","iopub.status.idle":"2024-06-05T08:26:08.023965Z","shell.execute_reply.started":"2024-06-05T08:26:07.984602Z","shell.execute_reply":"2024-06-05T08:26:08.022623Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   score  word_count  essay_length  sentences_count  paragraph_count  \\\n0      3         545          2677               13                1   \n1      3         371          1669               19                9   \n2      4         605          3077               24                7   \n3      4         511          2701               23                9   \n4      3         418          2208               15               11   \n\n   unique_word_count  text_length_p  word_count_p  unique_word_count_p  \\\n0                248           2640           539                  227   \n1                168           1663           371                  152   \n2                243           3065           605                  231   \n3                241           2674           502                  223   \n4                156           2184           417                  148   \n\n   flesch_reading_ease  ...  linsear_write_formula  gunning_fog  \\\n0                58.69  ...              13.000000        17.08   \n1                87.55  ...               6.714286         7.48   \n2                65.15  ...              15.500000        11.49   \n3                58.62  ...              15.750000        11.85   \n4                54.76  ...              19.666667        12.61   \n\n   text_standard  spache_readability  mcalpine_efg_time  syllablaw  \\\n0           12.0                7.20              31.58       53.4   \n1            7.0                3.92              19.57       25.7   \n2           12.0                5.12              36.96       32.6   \n3           13.0                5.32              32.74       28.9   \n4           13.0                5.61              26.62       35.6   \n\n   readinle_count  lexicon_count  monosyllabcount  \\\n0             624            489              396   \n1             398            332              275   \n2             767            550              417   \n3             678            441              284   \n4             561            372              240   \n\n                                          clean_text  \n0  many people have car where they live the thing...  \n1  i am a scientist at nasa that is discussing th...  \n2  people always wish they had the same technolog...  \n3  we all heard about venus the planet without al...  \n4  dear state senator  this is a letter to argue ...  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>word_count</th>\n      <th>essay_length</th>\n      <th>sentences_count</th>\n      <th>paragraph_count</th>\n      <th>unique_word_count</th>\n      <th>text_length_p</th>\n      <th>word_count_p</th>\n      <th>unique_word_count_p</th>\n      <th>flesch_reading_ease</th>\n      <th>...</th>\n      <th>linsear_write_formula</th>\n      <th>gunning_fog</th>\n      <th>text_standard</th>\n      <th>spache_readability</th>\n      <th>mcalpine_efg_time</th>\n      <th>syllablaw</th>\n      <th>readinle_count</th>\n      <th>lexicon_count</th>\n      <th>monosyllabcount</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>545</td>\n      <td>2677</td>\n      <td>13</td>\n      <td>1</td>\n      <td>248</td>\n      <td>2640</td>\n      <td>539</td>\n      <td>227</td>\n      <td>58.69</td>\n      <td>...</td>\n      <td>13.000000</td>\n      <td>17.08</td>\n      <td>12.0</td>\n      <td>7.20</td>\n      <td>31.58</td>\n      <td>53.4</td>\n      <td>624</td>\n      <td>489</td>\n      <td>396</td>\n      <td>many people have car where they live the thing...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>371</td>\n      <td>1669</td>\n      <td>19</td>\n      <td>9</td>\n      <td>168</td>\n      <td>1663</td>\n      <td>371</td>\n      <td>152</td>\n      <td>87.55</td>\n      <td>...</td>\n      <td>6.714286</td>\n      <td>7.48</td>\n      <td>7.0</td>\n      <td>3.92</td>\n      <td>19.57</td>\n      <td>25.7</td>\n      <td>398</td>\n      <td>332</td>\n      <td>275</td>\n      <td>i am a scientist at nasa that is discussing th...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>605</td>\n      <td>3077</td>\n      <td>24</td>\n      <td>7</td>\n      <td>243</td>\n      <td>3065</td>\n      <td>605</td>\n      <td>231</td>\n      <td>65.15</td>\n      <td>...</td>\n      <td>15.500000</td>\n      <td>11.49</td>\n      <td>12.0</td>\n      <td>5.12</td>\n      <td>36.96</td>\n      <td>32.6</td>\n      <td>767</td>\n      <td>550</td>\n      <td>417</td>\n      <td>people always wish they had the same technolog...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>511</td>\n      <td>2701</td>\n      <td>23</td>\n      <td>9</td>\n      <td>241</td>\n      <td>2674</td>\n      <td>502</td>\n      <td>223</td>\n      <td>58.62</td>\n      <td>...</td>\n      <td>15.750000</td>\n      <td>11.85</td>\n      <td>13.0</td>\n      <td>5.32</td>\n      <td>32.74</td>\n      <td>28.9</td>\n      <td>678</td>\n      <td>441</td>\n      <td>284</td>\n      <td>we all heard about venus the planet without al...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>418</td>\n      <td>2208</td>\n      <td>15</td>\n      <td>11</td>\n      <td>156</td>\n      <td>2184</td>\n      <td>417</td>\n      <td>148</td>\n      <td>54.76</td>\n      <td>...</td>\n      <td>19.666667</td>\n      <td>12.61</td>\n      <td>13.0</td>\n      <td>5.61</td>\n      <td>26.62</td>\n      <td>35.6</td>\n      <td>561</td>\n      <td>372</td>\n      <td>240</td>\n      <td>dear state senator  this is a letter to argue ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:26:08.025808Z","iopub.execute_input":"2024-06-05T08:26:08.026276Z","iopub.status.idle":"2024-06-05T08:26:08.050216Z","shell.execute_reply.started":"2024-06-05T08:26:08.026239Z","shell.execute_reply":"2024-06-05T08:26:08.048600Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 26 columns):\n #   Column                        Non-Null Count  Dtype  \n---  ------                        --------------  -----  \n 0   score                         17307 non-null  int64  \n 1   word_count                    17307 non-null  int64  \n 2   essay_length                  17307 non-null  int64  \n 3   sentences_count               17307 non-null  int64  \n 4   paragraph_count               17307 non-null  int64  \n 5   unique_word_count             17307 non-null  int64  \n 6   text_length_p                 17307 non-null  int64  \n 7   word_count_p                  17307 non-null  int64  \n 8   unique_word_count_p           17307 non-null  int64  \n 9   flesch_reading_ease           17307 non-null  float64\n 10  flesch_kincaid_grade          17307 non-null  float64\n 11  smog_index                    17307 non-null  float64\n 12  coleman_liau_index            17307 non-null  float64\n 13  automated_readability_index   17307 non-null  float64\n 14  dale_chall_readability_score  17307 non-null  float64\n 15  difficult_words               17307 non-null  int64  \n 16  linsear_write_formula         17307 non-null  float64\n 17  gunning_fog                   17307 non-null  float64\n 18  text_standard                 17307 non-null  float64\n 19  spache_readability            17307 non-null  float64\n 20  mcalpine_efg_time             17307 non-null  float64\n 21  syllablaw                     17307 non-null  float64\n 22  readinle_count                17307 non-null  int64  \n 23  lexicon_count                 17307 non-null  int64  \n 24  monosyllabcount               17307 non-null  int64  \n 25  clean_text                    17307 non-null  object \ndtypes: float64(12), int64(13), object(1)\nmemory usage: 3.4+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Cài đặt Pipeline","metadata":{}},{"cell_type":"markdown","source":"**Câu hỏi**: Pipeline là gì?\n\n> Pipeline là một cách để mã hóa và tự động hóa các công đoạn và quy trình làm việc cần thiết để tạo ra một mô hình học máy. Pipeline bao gồm nhiều bước tuần tự thực hiện mọi thứ từ trích xuất dữ liệu (data extraction) và tiền xử lý dữ liệu (preprocessing data) cho đến huấn luyện và triển khai mô hình.\n\n> Đối với các hệ thống sử dụng mô hình ML, thì quy trình pipeline là phần trung tâm của sản phẩm. Nó đóng gói toàn bộ các phương pháp xử lý dữ liệu tốt nhất để tạo ra một mô hình học máy phù hợp nhất cho một bộ dữ liệu cụ thể. Ngoài ra pipeline còn cho phép mô hình thực thi trên quy mô lớn. Một thiết kế pipeline end-to-end sẽ cho phép hệ thống của bạn cập nhật một cách thường xuyên các mô hình học máy một cách nhanh chóng.","metadata":{}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(\n            tokenizer=lambda x: x,\n            preprocessor=lambda x: x,\n            token_pattern=None,\n            strip_accents='unicode',\n            analyzer = 'word',\n            ngram_range=(3,6),\n            min_df=0.05,\n            max_df=0.95,\n            sublinear_tf=True,\n)\n\ntrain_tfid = vectorizer.fit_transform([i for i in df_train['clean_text']])\ndense_matrix = train_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:26:08.051893Z","iopub.execute_input":"2024-06-05T08:26:08.052396Z","iopub.status.idle":"2024-06-05T08:30:29.768271Z","shell.execute_reply.started":"2024-06-05T08:26:08.052341Z","shell.execute_reply":"2024-06-05T08:30:29.766759Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df_train = pd.concat([df_train, df], axis = 1)\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:30:29.770116Z","iopub.execute_input":"2024-06-05T08:30:29.770587Z","iopub.status.idle":"2024-06-05T08:30:44.131844Z","shell.execute_reply.started":"2024-06-05T08:30:29.770545Z","shell.execute_reply":"2024-06-05T08:30:44.130569Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   score  word_count  essay_length  sentences_count  paragraph_count  \\\n0      3         545          2677               13                1   \n1      3         371          1669               19                9   \n2      4         605          3077               24                7   \n3      4         511          2701               23                9   \n4      3         418          2208               15               11   \n\n   unique_word_count  text_length_p  word_count_p  unique_word_count_p  \\\n0                248           2640           539                  227   \n1                168           1663           371                  152   \n2                243           3065           605                  231   \n3                241           2674           502                  223   \n4                156           2184           417                  148   \n\n   flesch_reading_ease  ...  tfid_18991  tfid_18992  tfid_18993  tfid_18994  \\\n0                58.69  ...     0.00000    0.000000         0.0         0.0   \n1                87.55  ...     0.00000    0.000000         0.0         0.0   \n2                65.15  ...     0.00000    0.000000         0.0         0.0   \n3                58.62  ...     0.01548    0.015657         0.0         0.0   \n4                54.76  ...     0.00000    0.000000         0.0         0.0   \n\n   tfid_18995  tfid_18996  tfid_18997  tfid_18998  tfid_18999  tfid_19000  \n0         0.0         0.0         0.0         0.0         0.0     0.01778  \n1         0.0         0.0         0.0         0.0         0.0     0.00000  \n2         0.0         0.0         0.0         0.0         0.0     0.00000  \n3         0.0         0.0         0.0         0.0         0.0     0.00000  \n4         0.0         0.0         0.0         0.0         0.0     0.00000  \n\n[5 rows x 19027 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>word_count</th>\n      <th>essay_length</th>\n      <th>sentences_count</th>\n      <th>paragraph_count</th>\n      <th>unique_word_count</th>\n      <th>text_length_p</th>\n      <th>word_count_p</th>\n      <th>unique_word_count_p</th>\n      <th>flesch_reading_ease</th>\n      <th>...</th>\n      <th>tfid_18991</th>\n      <th>tfid_18992</th>\n      <th>tfid_18993</th>\n      <th>tfid_18994</th>\n      <th>tfid_18995</th>\n      <th>tfid_18996</th>\n      <th>tfid_18997</th>\n      <th>tfid_18998</th>\n      <th>tfid_18999</th>\n      <th>tfid_19000</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>545</td>\n      <td>2677</td>\n      <td>13</td>\n      <td>1</td>\n      <td>248</td>\n      <td>2640</td>\n      <td>539</td>\n      <td>227</td>\n      <td>58.69</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.01778</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>371</td>\n      <td>1669</td>\n      <td>19</td>\n      <td>9</td>\n      <td>168</td>\n      <td>1663</td>\n      <td>371</td>\n      <td>152</td>\n      <td>87.55</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>605</td>\n      <td>3077</td>\n      <td>24</td>\n      <td>7</td>\n      <td>243</td>\n      <td>3065</td>\n      <td>605</td>\n      <td>231</td>\n      <td>65.15</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>511</td>\n      <td>2701</td>\n      <td>23</td>\n      <td>9</td>\n      <td>241</td>\n      <td>2674</td>\n      <td>502</td>\n      <td>223</td>\n      <td>58.62</td>\n      <td>...</td>\n      <td>0.01548</td>\n      <td>0.015657</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>418</td>\n      <td>2208</td>\n      <td>15</td>\n      <td>11</td>\n      <td>156</td>\n      <td>2184</td>\n      <td>417</td>\n      <td>148</td>\n      <td>54.76</td>\n      <td>...</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 19027 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:30:44.133154Z","iopub.execute_input":"2024-06-05T08:30:44.133509Z","iopub.status.idle":"2024-06-05T08:30:45.426557Z","shell.execute_reply.started":"2024-06-05T08:30:44.133480Z","shell.execute_reply":"2024-06-05T08:30:45.425109Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nColumns: 19027 entries, score to tfid_19000\ndtypes: float64(19013), int64(13), object(1)\nmemory usage: 2.5+ GB\n","output_type":"stream"}]},{"cell_type":"code","source":"text_df = df_train['clean_text']\ndf_train = df_train.drop('clean_text', axis=1).astype('float64')","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:30:45.428205Z","iopub.execute_input":"2024-06-05T08:30:45.428682Z","iopub.status.idle":"2024-06-05T08:30:50.804901Z","shell.execute_reply.started":"2024-06-05T08:30:45.428639Z","shell.execute_reply":"2024-06-05T08:30:50.803590Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(\"Start running...\")\n# Define transformers for numerical and categorical columns\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\n# Update categorical and numerical columns\nnumerical_columns = df_train.select_dtypes(include=['int64', 'float64']).columns\ncategorical_columns = df_train.select_dtypes('object').columns\n\n# Remove target variable from numerical columns\nnumerical_columns = numerical_columns.drop('score')\n\nprint(\"- Numerical collumns: \", numerical_columns)\nprint(\"\\n- Categorical collumns: \", categorical_columns)\n\n# Combine transformers using ColumnTransformer\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_columns),\n    ],remainder = 'passthrough')\n\n# Create a pipeline with the preprocessor\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor)])","metadata":{"execution":{"iopub.status.busy":"2024-06-05T08:38:36.105178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the pipeline to your dataset\nX = df_train.drop(['score'], axis=1).astype('float32')\nX = X.apply(pd.to_numeric, errors='coerce')\ny = np.log(df_train['score'])\n\nX_preprocessed = pipeline.fit_transform(X)\nprint(\"This Pipeline is done\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# After Pipeline\n# Features columns have been normalized using StandardScaler()\nprint(X_preprocessed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Chia thành các tập train và tập test cho mô hình","metadata":{}},{"cell_type":"code","source":"# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, \n                                                    test_size=0.2, random_state=42)\n\nprint(\"Train set shape: \", X_train.shape, \" ; \", y_train.shape)\nprint(\"Test set shape: \",X_test.shape, \" ; \" ,y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cài đặt chấm điểm dựa theo cách chấm điểm của cuộc thi\n\n> Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement).\n\nCác bài nộp được tính điểm dựa trên kappa có trọng số bậc hai, thước đo sự phù hợp giữa hai kết quả. Số liệu này thường thay đổi từ 0 (thỏa thuận ngẫu nhiên) đến 1 (thỏa thuận hoàn chỉnh).","metadata":{}},{"cell_type":"code","source":"# # idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\ndef quadratic_weighted_kappa(y_true, y_pred):\n#     y_pred_exp = np.exp(y_pred)  # Chuyển đổi từ log-space về giá trị thực\n#     y_pred_exp = y_pred_exp.clip(1, 6).round()  # Giới hạn giá trị giữa 1 và 6 và làm tròn\n\n#     y_true_exp = np.round(np.exp(y_true))  # Chuyển đổi từ log-space về giá trị thực\n    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n\n# metric and objective based on public notebooks\ndef qwk_obj(y_true, y_pred):\n    labels = y_true + a\n    preds = y_pred + a\n    preds = preds.clip(1, 6)\n    f = 1/2*np.sum((preds-labels)**2)\n    g = 1/2*np.sum((preds-a)**2+b)\n    df = preds - labels\n    dg = preds - a\n    grad = (df/g - f*dg/g**2)*len(labels)\n    hess = np.ones(len(labels))\n    return grad, hess\n\na = 2.998\nb = 1.092","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Huấn luyện mô hình","metadata":{}},{"cell_type":"code","source":"# print(\"Start running...\")\n\n# # Create a scorer for QWK\n# qwk_scorer = make_scorer(quadratic_weighted_kappa, greater_is_better=True)\n# eval_results = []\n\n# # Cài đặt KFold\n# kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n\n# xgb_callbacks = [\n#     xgb.callback.EvaluationMonitor(period=25),\n#     xgb.callback.EarlyStopping(75, metric_name=\"QWK\", maximize=True, save_best=True)\n# ]\n\n# xgb_regressor = xgb.XGBRegressor(\n#     objective=qwk_obj,  # Use custom QWK objective function\n#     n_estimators= 207,\n#     learning_rate= 0.10704240620854825,\n#     min_split_loss = 1,\n#     max_depth= 6,\n#     subsample= 0.6389081081835488,\n#     max_bin = 337,\n#     random_state=42,\n#     num_leaves = 10,\n#     extra_trees=True,\n#     class_weight='balanced',\n#     tree_method=\"hist\"\n# )\n\n# # Define evaluation sets for early stopping and monitoring\n# eval_set = [(X_test, y_test)]\n\n# # Train the model\n# xgb_regressor.fit(X_train, y_train)\n# #                 eval_set=eval_set,\n# #                 eval_metric=quadratic_weighted_kappa, \n# #                 callbacks=xgb_callbacks,\n# #                 verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Start running...\")\n\n# # Create a scorer for QWK\n# qwk_scorer = make_scorer(quadratic_weighted_kappa, greater_is_better=True)\n# eval_results = []\n\n# # Cài đặt KFold\n# kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n\n# lgbm_regressor = lgb.LGBMRegressor(\n#     objective = qwk_obj,\n#     num_leaves = 10,\n#     min_data_in_leaf = 100,\n#     max_depth = 6,\n#     n_estimators = 248,\n#     random_state = 42,\n#     max_bin = 288,\n#     num_iterations = 120,\n#     bagging_freq = 12,\n#     extra_trees = True,\n#     class_weight = 'balanced')\n\n\n# # Define evaluation sets for early stopping and monitoring\n# eval_set = [(X_test, y_test)]\n\n# # Train the model\n# lgbm_regressor.fit(X_train, y_train)\n# #                 eval_set=eval_set,\n# #                 eval_metric=quadratic_weighted_kappa, \n# #                 callbacks=xgb_callbacks,\n# #                 verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Make predictions on the validation set\n# y_pred = xgb_regressor.predict(X_test)\n\n# y_pred = np.exp(y_pred)  # Chuyển đổi từ log-space về giá trị thực\n# y_pred = y_pred.clip(1, 6).round()  # Giới hạn giá trị giữa 1 và 6 và làm tròn\n\n# y_test = np.round(np.exp(y_test))  # Chuyển đổi từ log-space về giá trị thực\n\n# # Calculate the Cohen's kappa score\n# score = quadratic_weighted_kappa(y_test, y_pred)\n# print(f\"Train QWK: {score:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Make predictions on the validation set\n# y_pred = lgbm_regressor.predict(X_test)\n\n# y_pred = np.exp(y_pred)  # Chuyển đổi từ log-space về giá trị thực\n# y_pred = y_pred.clip(1, 6).round()  # Giới hạn giá trị giữa 1 và 6 và làm tròn\n\n# y_test = np.round(np.exp(y_test))  # Chuyển đổi từ log-space về giá trị thực\n\n# # Calculate the Cohen's kappa score\n# score = quadratic_weighted_kappa(y_test, y_pred)\n# print(f\"Train QWK: {score:.3f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_idx = 1\n# for train_ids, val_ids in kfold.split(X, y):\n\n#     xgb_regressor = xgb.XGBRegressor(\n#     objective=qwk_obj,  # Use custom QWK objective function\n#     n_estimators= 207,\n#     learning_rate= 0.10704240620854825,\n#     min_split_loss = 1,\n#     max_depth= 6,\n#     subsample= 0.6389081081835488,\n#     max_bin = 337,\n#     random_state=42,\n#     num_leaves = 10,\n#     extra_trees=True,\n#     class_weight='balanced',\n#     tree_method=\"hist\"\n#     )\n\n#     print(\"Bắt đầu train Fold \", fold_idx)\n\n#     # Train model\n#     xgb_regressor.fit(X[train_ids], y[train_ids],\n#               batch_size=batch_size,\n#               epochs=no_epochs,\n#               verbose=1)\n\n#     # Test và in kết quả\n#     y_pred = xgb_regressor.predict(X[train_ids])\n#     # Calculate the Cohen's kappa score\n#     score = quadratic_weighted_kappa(y[train_ids], y_pred)\n#     print(\"Đã train xong Fold \", fold_idx)\n#     print(f\"Train QWK: {score:.3f}\")\n\n#     # Sang Fold tiếp theo\n#     fold_idx = fold_idx + 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dự đoán kết quả bằng mô hình vừa huấn luyện","metadata":{}},{"cell_type":"markdown","source":"### Optuna\n\n> An open source hyperparameter optimization framework to automate hyperparameter search","metadata":{}},{"cell_type":"markdown","source":" **Câu hỏi**: Khó khăn gặp phải khi phải điều chỉnh tham số thủ công?\n \n - Việc chọn siêu tham số khi thực hiện training mô hình dường như đều dựa vào cảm tính và kinh nghiệm của người lập trình. Và điều nay không phải lúc nào cũng có thể làm cho mô hình đạt hiệu suất, kết quả tốt nhất . Còn đối với những lập trình viên chưa có kinh nghiệm lựa chọn siêu tham số thì đây thực sự là một thử thách khi đòi hỏi phải có kiến thức và kinh nghiệm nhất định.","metadata":{}},{"cell_type":"markdown","source":" **Câu hỏi**: Optuna là gì ?\n \n - Optuna là 1 framework hỗ trợ việc tự động điều chỉnh tham số mô hình để mô hình có thể đạt được hiệu năng tốt nhất. Do đó giúp giảm bớt thời gian và công sức khi chúng ta không cần phải điều chỉnh các siêu tham số một cách thủ công nữa. Từ đó giúp tăng năng suất công việc.","metadata":{}},{"cell_type":"markdown","source":"#### Định nghĩa objective function\n\n**Trial object definition**: \n\n> Trial là một đối tượng thể hiện của một class được thực thi trong Optuna.Nó được sử dụng để định nghĩa các siêu tham số được tối ưu. Giá trị được lấy trong phạm vi được định nghĩa, thông tin của các tham số được tìm kiếm trong quá khứ vẫn được giữ lại và giá trị mới sẽ dựa trên những thông tin đó. \n\nHay dễ hiểu hơn là Optuna sẽ duyệt qua các tham số được cài đặt thử nghiệm và chọn tập hợp siêu tham số có kết quả tốt nhất là tham số sử dụng cho mô hình cuối cùng.","metadata":{}},{"cell_type":"code","source":"# def objective(trial):\n#     param_grid = {\n#         'n_estimators': trial.suggest_int('n_estimators', 500, 700),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n#         'min_split_loss': trial.suggest_int('min_split_loss', 0, 9),\n#         'max_depth': trial.suggest_int('max_depth', 6, 12),\n#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n#         'max_bin': trial.suggest_int('max_bin', 256, 512)\n#     }\n\n#     xgb_regressor = xgb.XGBRegressor(\n#         objective=qwk_obj,\n#         random_state=42,\n#         tree_method=\"hist\",\n#         **param_grid\n#     )\n    \n#     xgb_regressor.fit(X_train, y_train)\n    \n#     y_pred_log = xgb_regressor.predict(X_test)\n#     y_pred = np.exp(y_pred_log)\n#     # y_pred = y_pred + a\n#     y_pred = y_pred.clip(1, 6).round()\n#     y_test_exp = np.exp(y_test)\n\n#     # Calculate the Cohen's kappa score\n#     score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n#     return np.mean(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    param_grid = {\n        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 60, 120),\n        'max_depth': trial.suggest_int('max_depth', 6, 12),\n        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n        'max_bin': trial.suggest_int('max_bin', 200, 400),\n        'bagging_freq': trial.suggest_int('bagging_freq', 10, 14)\n    }\n\n    lgbm_regressor = lgb.LGBMRegressor(\n        objective=qwk_obj,\n        random_state=42,\n        extra_trees = True,\n         class_weight = 'balanced',\n        **param_grid\n    )\n    \n    lgbm_regressor.fit(X_train, y_train)\n    \n    y_pred_log = lgbm_regressor.predict(X_test)\n    y_pred = np.exp(y_pred_log)\n    # y_pred = y_pred + a\n    y_pred = y_pred.clip(1, 6).round()\n    y_test_exp = np.exp(y_test)\n\n    # Calculate the Cohen's kappa score\n    score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n    return np.mean(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Định nghĩa study object**: Để tìm kiếm siêu tham số, bạn cần khởi tạo một đối tượng là study \n\n> Đối tượng này lưu kết quả tối ưu của bạn.\n\n**Sau đó, sử dụng phương thức optimize**:\n\n- Trong đó, tham số thứ 1 là hàm Objective \n- Tham số thứ 2 là số lượng thử nghiệm. \n\n> Quá trình tối ưu này được thực hiện trong đối tượng Study và sẽ thực hiện tìm giá trị cực tiểu của các tham số trong hàm Objective bằng phương pháp tối ưu hóa. ","metadata":{}},{"cell_type":"code","source":"# Set up the Optuna study\nstudy = optuna.create_study(direction='maximize', sampler=TPESampler())\nstudy.optimize(objective, n_trials=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Khi kết thúc quá trình trên, giá trị tối ưu sẽ được lưu lại và bạn có thể xem nó bằng câu lệnh sau:","metadata":{}},{"cell_type":"code","source":"# Get the best hyperparameters\nbest_params = study.best_params\nprint(\"Best Hyperparameters:\", best_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Thực hiện áp dụng các siêu tham số mà framework Optuna đã huấn luyện và chọn lọc","metadata":{}},{"cell_type":"code","source":"# # Train the final model with the best hyperparameters\n# xgb_regressor = xgb.XGBRegressor(\n#     objective=qwk_obj,\n#     random_state=42,\n#     **best_params\n# )\n\n# xgb_regressor.fit(\n#     X_train, y_train,\n#     early_stopping_rounds=10,\n#     eval_set=[(X_test, y_test)],\n#     verbose=True\n# )\n\n# y_pred_log = xgb_regressor.predict(X_test)\n# y_pred = np.exp(y_pred_log)\n# # y_pred = y_pred + a\n# y_pred = y_pred.clip(1, 6).round()\n# y_test_exp = np.exp(y_test)\n\n# # Calculate the Cohen's kappa score\n# score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n# print(f\"Train QWK: {score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the final model with the best hyperparameters\nlgbm_regressor = lgb.LGBMRegressor(\n    objective=qwk_obj,\n    random_state=42,\n    **best_params\n)\n\nlgbm_regressor.fit(\n    X_train, y_train,\n    early_stopping_rounds=10,\n    eval_set=[(X_test, y_test)],\n    verbose=True\n)\n\ny_pred_log = lgbm_regressor.predict(X_test)\ny_pred = np.exp(y_pred_log)\n# y_pred = y_pred + a\ny_pred = y_pred.clip(1, 6).round()\ny_test_exp = np.exp(y_test)\n\n# Calculate the Cohen's kappa score\nscore = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\nprint(f\"Train QWK: {score}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Thực hiện áp dụng Model đã huấn luyện vào file test.csv","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')\ndf_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = preprocess_df(df_test)\ndf_test['clean_text'] = df_test['full_text'].apply(clean_text)\ndf_test = df_test.drop('full_text', axis = 1)\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Xuất kết quả ra file submission và nộp bài","metadata":{}},{"cell_type":"code","source":"# Lưu lại cột essay_id để sử dụng sau này\nessay_ids = df_test['essay_id']\n\ntest_tfid = vectorizer.transform([i for i in df_test['clean_text']])\ndense_matrix = test_tfid.toarray()\ndf = pd.DataFrame(dense_matrix)\ntfid_columns = [ f'tfid_{i}' for i in range(len(df.columns))]\ndf.columns = tfid_columns\n\ndf_test = pd.concat([df_test, df], axis = 1)\nX_test = df_test.drop(['clean_text', 'essay_id'], axis=1).astype('float64')\n\nX_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test.dtypes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Áp dụng pipeline đã huấn luyện để tiền xử lý dữ liệu test\n# X_test_preprocessed = pipeline.transform(X_test)\n\n# # Dự đoán điểm số trên dữ liệu test đã tiền xử lý\n# y_pred_log = xgb_regressor.predict(X_test_preprocessed)\n\n# # Chuyển đổi ngược từ log-transform\n# y_pred = np.exp(y_pred_log)\n\n# # Tạo dataframe chứa essay_id và dự đoán điểm số\n# results = pd.DataFrame({'essay_id': essay_ids, 'score': y_pred})\n\n# # Làm tròn điểm số\n# results['score'] = round(results['score'])\n# results['score'] = results['score'].astype(int)\n\n# # Lưu kết quả ra file csv\n# submission = results.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Áp dụng pipeline đã huấn luyện để tiền xử lý dữ liệu test\nX_test_preprocessed = pipeline.transform(X_test)\n\n# Dự đoán điểm số trên dữ liệu test đã tiền xử lý\ny_pred_log = lgbm_regressor.predict(X_test_preprocessed)\n\n# Chuyển đổi ngược từ log-transform\ny_pred = np.exp(y_pred_log)\n\n# Tạo dataframe chứa essay_id và dự đoán điểm số\nresults = pd.DataFrame({'essay_id': essay_ids, 'score': y_pred})\n\n# Làm tròn điểm số\nresults['score'] = round(results['score'])\nresults['score'] = results['score'].astype(int)\n\n# Lưu kết quả ra file csv\nsubmission = results.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}