{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":8404441,"sourceType":"datasetVersion","datasetId":4956698}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Decomment this line of code if you already have those downloaded\n!pip install --no-index --no-deps /kaggle/input/aes-whls/aes_whls/pyphen-0.15.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/aes-whls/aes_whls/textstat-0.7.3-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:49.429701Z","iopub.execute_input":"2024-05-29T04:17:49.430331Z","iopub.status.idle":"2024-05-29T04:17:54.349739Z","shell.execute_reply.started":"2024-05-29T04:17:49.430287Z","shell.execute_reply":"2024-05-29T04:17:54.348038Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/aes-whls/aes_whls/pyphen-0.15.0-py3-none-any.whl\npyphen is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nProcessing /kaggle/input/aes-whls/aes_whls/textstat-0.7.3-py3-none-any.whl\ntextstat is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Basic libary\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport torch\nimport re\nimport optuna\nimport textstat\nfrom optuna.samplers import TPESampler\n# cmap = plt.cm.get_cmap('coolwarm')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Use for pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import cohen_kappa_score, f1_score, make_scorer\n\n# Use for training model\nfrom scipy.stats import randint\nfrom nltk.tokenize import word_tokenize\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier \nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import RandomizedSearchCV\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-05-29T04:17:54.352424Z","iopub.execute_input":"2024-05-29T04:17:54.352815Z","iopub.status.idle":"2024-05-29T04:17:54.371774Z","shell.execute_reply.started":"2024-05-29T04:17:54.352782Z","shell.execute_reply":"2024-05-29T04:17:54.370629Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ndf_test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:54.373614Z","iopub.execute_input":"2024-05-29T04:17:54.374154Z","iopub.status.idle":"2024-05-29T04:17:54.834494Z","shell.execute_reply.started":"2024-05-29T04:17:54.374113Z","shell.execute_reply":"2024-05-29T04:17:54.833350Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"essay_id_dropped = df_train['essay_id']\ndf_train = df_train.drop('essay_id', axis = 1)\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:54.839666Z","iopub.execute_input":"2024-05-29T04:17:54.840046Z","iopub.status.idle":"2024-05-29T04:17:54.876261Z","shell.execute_reply.started":"2024-05-29T04:17:54.840017Z","shell.execute_reply":"2024-05-29T04:17:54.874996Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   full_text  17307 non-null  object\n 1   score      17307 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 270.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:54.878004Z","iopub.execute_input":"2024-05-29T04:17:54.878344Z","iopub.status.idle":"2024-05-29T04:17:54.892530Z","shell.execute_reply.started":"2024-05-29T04:17:54.878318Z","shell.execute_reply":"2024-05-29T04:17:54.891069Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                           full_text  score\n0  Many people have car where they live. The thin...      3\n1  I am a scientist at NASA that is discussing th...      3\n2  People always wish they had the same technolog...      4\n3  We all heard about Venus, the planet without a...      4\n4  Dear, State Senator\\n\\nThis is a letter to arg...      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Many people have car where they live. The thin...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am a scientist at NASA that is discussing th...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>People always wish they had the same technolog...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We all heard about Venus, the planet without a...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\n\ndef dataPreprocessing(x):\n    # Convert words to lowercase\n    x = x.lower()\n    # Remove HTML\n    x = removeHTML(x)\n    # Delete strings starting with @\n    x = re.sub(\"@\\w+\", '',x)\n    # Delete Numbers\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    # Delete URL\n    x = re.sub(\"http\\w+\", '',x)\n    # Replace consecutive empty spaces with a single space character\n    x = re.sub(r\"\\s+\", \" \", x)\n    # Replace consecutive commas and periods with one comma and period character\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = re.sub(r'\\xa0', '', x)\n    # Remove empty characters at the beginning and end\n    x = x.strip()\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:54.894470Z","iopub.execute_input":"2024-05-29T04:17:54.894941Z","iopub.status.idle":"2024-05-29T04:17:54.904212Z","shell.execute_reply.started":"2024-05-29T04:17:54.894891Z","shell.execute_reply":"2024-05-29T04:17:54.902987Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def textstat_features(text):\n    features = {}\n    features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n    features['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n    features['smog_index'] = textstat.smog_index(text)\n    features['coleman_liau_index'] = textstat.coleman_liau_index(text)\n    features['automated_readability_index'] = textstat.automated_readability_index(text)\n    features['dale_chall_readability_score'] = textstat.dale_chall_readability_score(text)\n    features['difficult_words'] = textstat.difficult_words(text)\n    features['linsear_write_formula'] = textstat.linsear_write_formula(text)\n    features['gunning_fog'] = textstat.gunning_fog(text)\n    features['text_standard'] = textstat.text_standard(text, float_output=True)\n    features['spache_readability'] = textstat.spache_readability(text)\n    features['mcalpine_efg_time'] = textstat.reading_time(text)\n    features['syllablaw'] = textstat.mcalpine_eflaw(text)\n    features['readinle_count'] = textstat.syllable_count(text)\n    features['lexicon_count'] = textstat.lexicon_count(text)\n    features['monosyllabcount'] = textstat.monosyllabcount(text)\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:54.905799Z","iopub.execute_input":"2024-05-29T04:17:54.906444Z","iopub.status.idle":"2024-05-29T04:17:54.917019Z","shell.execute_reply.started":"2024-05-29T04:17:54.906412Z","shell.execute_reply":"2024-05-29T04:17:54.915663Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Number of words\nimport string\ndef preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n\n    # Length\n    df['essay_length'] = df['full_text'].str.len()\n\n    # Sentences count\n    # Adding a new column 'sentences_count' that counts the sentences in 'full_text'\n    df['sentences_count'] = df['full_text'].str.count(r'\\.')\n\n    # Paragraph count\n    # Adding a new column 'paragraph_count' that counts the paragraphs in 'full_text'\n    df['paragraph_count'] = df['full_text'].str.count(r'\\n') + 1\n    \n    df[\"text_tokens\"] = df[\"full_text\"].apply(lambda x: word_tokenize(x))\n    df[\"word_count\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n    df[\"unique_word_count\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n    df.drop(columns=[\"text_tokens\"], inplace=True)\n    \n    df[\"processed_text\"] = df[\"full_text\"].apply(lambda x: dataPreprocessing(x))\n    df[\"text_tokens\"] = df[\"processed_text\"].apply(lambda x: word_tokenize(x))\n    df[\"text_length_p\"] = df[\"processed_text\"].apply(lambda x: len(x))\n    df[\"word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(x))\n    df[\"unique_word_count_p\"] = df[\"text_tokens\"].apply(lambda x: len(set(x)))\n    \n    # Applying textstat features\n    df['textstat_features'] = df['processed_text'].apply(textstat_features)\n    textstat_df = pd.DataFrame(df['textstat_features'].tolist())\n    df = pd.concat([df, textstat_df], axis=1)\n\n    df.drop(columns=[\"processed_text\", \"text_tokens\", \"textstat_features\"], inplace=True)\n    \n    return df\n\ndef clean_text(text):\n    text = re.sub(r'\\n', ' ', text)  # Loại bỏ xuống dòng\n    text = re.sub(r'[^\\w\\s]', '', text)  # Loại bỏ ký tự đặc biệt\n    text = re.sub(r'\\xa0', '', text)\n    text = text.lower()  # Chuyển thành chữ thường\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:54.918844Z","iopub.execute_input":"2024-05-29T04:17:54.919344Z","iopub.status.idle":"2024-05-29T04:17:54.937532Z","shell.execute_reply.started":"2024-05-29T04:17:54.919305Z","shell.execute_reply":"2024-05-29T04:17:54.936014Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_train = preprocess_df(df_train)\ndf_train['clean_text'] = df_train['full_text'].apply(clean_text)\ndf_train = df_train.drop('full_text', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:17:54.939303Z","iopub.execute_input":"2024-05-29T04:17:54.939918Z","iopub.status.idle":"2024-05-29T04:23:21.538295Z","shell.execute_reply.started":"2024-05-29T04:17:54.939857Z","shell.execute_reply":"2024-05-29T04:23:21.537030Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:21.544769Z","iopub.execute_input":"2024-05-29T04:23:21.545291Z","iopub.status.idle":"2024-05-29T04:23:21.584109Z","shell.execute_reply.started":"2024-05-29T04:23:21.545212Z","shell.execute_reply":"2024-05-29T04:23:21.582687Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   score  word_count  essay_length  sentences_count  paragraph_count  \\\n0      3         545          2677               13                1   \n1      3         371          1669               19                9   \n2      4         605          3077               24                7   \n3      4         511          2701               23                9   \n4      3         418          2208               15               11   \n\n   unique_word_count  text_length_p  word_count_p  unique_word_count_p  \\\n0                248           2640           539                  227   \n1                168           1663           371                  152   \n2                243           3065           605                  231   \n3                241           2674           502                  223   \n4                156           2184           417                  148   \n\n   flesch_reading_ease  ...  linsear_write_formula  gunning_fog  \\\n0                58.69  ...              13.000000        17.08   \n1                87.55  ...               6.714286         7.48   \n2                65.15  ...              15.500000        11.49   \n3                58.62  ...              15.750000        11.85   \n4                54.76  ...              19.666667        12.61   \n\n   text_standard  spache_readability  mcalpine_efg_time  syllablaw  \\\n0           12.0                7.20              31.58       53.4   \n1            7.0                3.92              19.57       25.7   \n2           12.0                5.12              36.96       32.6   \n3           13.0                5.32              32.74       28.9   \n4           13.0                5.61              26.62       35.6   \n\n   readinle_count  lexicon_count  monosyllabcount  \\\n0             624            489              396   \n1             398            332              275   \n2             767            550              417   \n3             678            441              284   \n4             561            372              240   \n\n                                          clean_text  \n0  many people have car where they live the thing...  \n1  i am a scientist at nasa that is discussing th...  \n2  people always wish they had the same technolog...  \n3  we all heard about venus the planet without al...  \n4  dear state senator  this is a letter to argue ...  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>word_count</th>\n      <th>essay_length</th>\n      <th>sentences_count</th>\n      <th>paragraph_count</th>\n      <th>unique_word_count</th>\n      <th>text_length_p</th>\n      <th>word_count_p</th>\n      <th>unique_word_count_p</th>\n      <th>flesch_reading_ease</th>\n      <th>...</th>\n      <th>linsear_write_formula</th>\n      <th>gunning_fog</th>\n      <th>text_standard</th>\n      <th>spache_readability</th>\n      <th>mcalpine_efg_time</th>\n      <th>syllablaw</th>\n      <th>readinle_count</th>\n      <th>lexicon_count</th>\n      <th>monosyllabcount</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>545</td>\n      <td>2677</td>\n      <td>13</td>\n      <td>1</td>\n      <td>248</td>\n      <td>2640</td>\n      <td>539</td>\n      <td>227</td>\n      <td>58.69</td>\n      <td>...</td>\n      <td>13.000000</td>\n      <td>17.08</td>\n      <td>12.0</td>\n      <td>7.20</td>\n      <td>31.58</td>\n      <td>53.4</td>\n      <td>624</td>\n      <td>489</td>\n      <td>396</td>\n      <td>many people have car where they live the thing...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>371</td>\n      <td>1669</td>\n      <td>19</td>\n      <td>9</td>\n      <td>168</td>\n      <td>1663</td>\n      <td>371</td>\n      <td>152</td>\n      <td>87.55</td>\n      <td>...</td>\n      <td>6.714286</td>\n      <td>7.48</td>\n      <td>7.0</td>\n      <td>3.92</td>\n      <td>19.57</td>\n      <td>25.7</td>\n      <td>398</td>\n      <td>332</td>\n      <td>275</td>\n      <td>i am a scientist at nasa that is discussing th...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>605</td>\n      <td>3077</td>\n      <td>24</td>\n      <td>7</td>\n      <td>243</td>\n      <td>3065</td>\n      <td>605</td>\n      <td>231</td>\n      <td>65.15</td>\n      <td>...</td>\n      <td>15.500000</td>\n      <td>11.49</td>\n      <td>12.0</td>\n      <td>5.12</td>\n      <td>36.96</td>\n      <td>32.6</td>\n      <td>767</td>\n      <td>550</td>\n      <td>417</td>\n      <td>people always wish they had the same technolog...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>511</td>\n      <td>2701</td>\n      <td>23</td>\n      <td>9</td>\n      <td>241</td>\n      <td>2674</td>\n      <td>502</td>\n      <td>223</td>\n      <td>58.62</td>\n      <td>...</td>\n      <td>15.750000</td>\n      <td>11.85</td>\n      <td>13.0</td>\n      <td>5.32</td>\n      <td>32.74</td>\n      <td>28.9</td>\n      <td>678</td>\n      <td>441</td>\n      <td>284</td>\n      <td>we all heard about venus the planet without al...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>418</td>\n      <td>2208</td>\n      <td>15</td>\n      <td>11</td>\n      <td>156</td>\n      <td>2184</td>\n      <td>417</td>\n      <td>148</td>\n      <td>54.76</td>\n      <td>...</td>\n      <td>19.666667</td>\n      <td>12.61</td>\n      <td>13.0</td>\n      <td>5.61</td>\n      <td>26.62</td>\n      <td>35.6</td>\n      <td>561</td>\n      <td>372</td>\n      <td>240</td>\n      <td>dear state senator  this is a letter to argue ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:21.585616Z","iopub.execute_input":"2024-05-29T04:23:21.585983Z","iopub.status.idle":"2024-05-29T04:23:21.605140Z","shell.execute_reply.started":"2024-05-29T04:23:21.585953Z","shell.execute_reply":"2024-05-29T04:23:21.603829Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 26 columns):\n #   Column                        Non-Null Count  Dtype  \n---  ------                        --------------  -----  \n 0   score                         17307 non-null  int64  \n 1   word_count                    17307 non-null  int64  \n 2   essay_length                  17307 non-null  int64  \n 3   sentences_count               17307 non-null  int64  \n 4   paragraph_count               17307 non-null  int64  \n 5   unique_word_count             17307 non-null  int64  \n 6   text_length_p                 17307 non-null  int64  \n 7   word_count_p                  17307 non-null  int64  \n 8   unique_word_count_p           17307 non-null  int64  \n 9   flesch_reading_ease           17307 non-null  float64\n 10  flesch_kincaid_grade          17307 non-null  float64\n 11  smog_index                    17307 non-null  float64\n 12  coleman_liau_index            17307 non-null  float64\n 13  automated_readability_index   17307 non-null  float64\n 14  dale_chall_readability_score  17307 non-null  float64\n 15  difficult_words               17307 non-null  int64  \n 16  linsear_write_formula         17307 non-null  float64\n 17  gunning_fog                   17307 non-null  float64\n 18  text_standard                 17307 non-null  float64\n 19  spache_readability            17307 non-null  float64\n 20  mcalpine_efg_time             17307 non-null  float64\n 21  syllablaw                     17307 non-null  float64\n 22  readinle_count                17307 non-null  int64  \n 23  lexicon_count                 17307 non-null  int64  \n 24  monosyllabcount               17307 non-null  int64  \n 25  clean_text                    17307 non-null  object \ndtypes: float64(12), int64(13), object(1)\nmemory usage: 3.4+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# rows_to_drop = df_train.query('sentences_count > 60 | (sentences_count > 50 & score == 1)').index\n\n# # Xóa các dòng có index tương ứng\n\n# df_train.drop(rows_to_drop, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:21.606611Z","iopub.execute_input":"2024-05-29T04:23:21.607463Z","iopub.status.idle":"2024-05-29T04:23:21.613325Z","shell.execute_reply.started":"2024-05-29T04:23:21.607413Z","shell.execute_reply":"2024-05-29T04:23:21.612079Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# rows_to_drop = df_train.query('paragraph_count > 80 | (paragraph_count > 55 & score == 1 ) | (paragraph_count >60 & score == 2 ) | (paragraph_count > 30  & score == 5) | (paragraph_count > 25  & score == 6)').index\n\n# # Xóa các dòng có index tương ứng\n\n# df_train.drop(rows_to_drop, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:21.614766Z","iopub.execute_input":"2024-05-29T04:23:21.615129Z","iopub.status.idle":"2024-05-29T04:23:21.630796Z","shell.execute_reply.started":"2024-05-29T04:23:21.615099Z","shell.execute_reply":"2024-05-29T04:23:21.629373Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Decomment if want to use Pipeline again\nprint(\"Start running...\")\n# Define transformers for numerical and categorical columns\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n])\n\n# Add text vectorization step\ntext_vectorizer = TfidfVectorizer(\n    encoding='utf-8',\n    ngram_range=(1, 3),\n    strip_accents='unicode',\n    analyzer='word',\n    min_df=0.05,\n    max_df=0.95,\n    sublinear_tf=True\n)\ntext_transformer = Pipeline(steps=[\n    ('vectorizer', text_vectorizer)\n])\n\n# Update categorical and numerical columns\nnumerical_columns = df_train.select_dtypes('int64').columns\ncategorical_columns = df_train.select_dtypes('object').columns\n\n# Remove target variable from numerical columns\nnumerical_columns = numerical_columns.drop('score')\n\n# Combine transformers using ColumnTransformer\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_columns),\n        ('cat', categorical_transformer, categorical_columns),\n        ('text', text_transformer, 'clean_text')  # Include the 'clean_text' column\n    ],remainder = 'passthrough')\n\n# Create a pipeline with the preprocessor\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor)])\n\n# Apply the pipeline to your dataset\nX = df_train.drop('score', axis=1)\ny = np.log(df_train['score'])\nX_preprocessed = pipeline.fit_transform(X)\nprint(\"This Pipeline is done\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:21.632230Z","iopub.execute_input":"2024-05-29T04:23:21.632585Z","iopub.status.idle":"2024-05-29T04:23:55.334390Z","shell.execute_reply.started":"2024-05-29T04:23:21.632558Z","shell.execute_reply":"2024-05-29T04:23:55.333245Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Start running...\nThis Pipeline is done\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, \n                                                    test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:55.337790Z","iopub.execute_input":"2024-05-29T04:23:55.338965Z","iopub.status.idle":"2024-05-29T04:23:56.485170Z","shell.execute_reply.started":"2024-05-29T04:23:55.338917Z","shell.execute_reply":"2024-05-29T04:23:56.483882Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# # idea from https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\ndef quadratic_weighted_kappa(y_pred, dtrain):\n    y_true = dtrain.get_label()\n    y_true = y_true + a\n    y_pred = (y_pred + a).clip(1, 6).round()\n    qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n    return 'QWK', qwk\n\n# metric and objective based on public notebooks\ndef qwk_obj(y_true, y_pred):\n    labels = y_true + a\n    preds = y_pred + a\n    preds = preds.clip(1, 6)\n    f = 1/2*np.sum((preds-labels)**2)\n    g = 1/2*np.sum((preds-a)**2+b)\n    df = preds - labels\n    dg = preds - a\n    grad = (df/g - f*dg/g**2)*len(labels)\n    hess = np.ones(len(labels))\n    return grad, hess\n\na = 2.998\nb = 1.092","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:56.486832Z","iopub.execute_input":"2024-05-29T04:23:56.487231Z","iopub.status.idle":"2024-05-29T04:23:56.497311Z","shell.execute_reply.started":"2024-05-29T04:23:56.487195Z","shell.execute_reply":"2024-05-29T04:23:56.495943Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# f1_scores = []\n# kappa_scores = []\n# predictions = []\n# # Define the models\n# models = {\n#     'XGBoost': XGBRegressor(random_state=42)\n# }\n\n# # Define the hyperparameter grids for each model\n# param_grids = {\n#     'XGBoost': {\n#         'n_estimators': [1024],\n#         'learning_rate': [0.1],\n#         'max_depth': [8],\n#         'subsample': [0.5],\n# #         'colsample_bytree': [0.5]\n#     }\n# }\n\n# # 3-fold cross-validation\n# cv = KFold(n_splits=3, shuffle=True, random_state=42)\n\n# # Train and tune the models\n# grids = {}\n# for model_name, model in models.items():\n#     grids[model_name] = GridSearchCV(estimator=model, param_grid=param_grids[model_name], \n#                                cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n#     grids[model_name].fit(X_train, y_train, eval_metric=quadratic_weighted_kappa)\n#     best_params = grids[model_name].best_params_\n#     best_score = np.sqrt(-1 * grids[model_name].best_score_)\n    \n#     print(f'Best parameters for {model_name}: {best_params}')\n#     print(f'Best RMSE for {model_name}: {best_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:56.498555Z","iopub.execute_input":"2024-05-29T04:23:56.498926Z","iopub.status.idle":"2024-05-29T04:23:56.515546Z","shell.execute_reply.started":"2024-05-29T04:23:56.498886Z","shell.execute_reply":"2024-05-29T04:23:56.514596Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(\"Start running...\")\n\n# # Define the hyperparameter grids for each model\n# param_grids = {\n#     \"n_estimators\": randint(100, 500),\n#     \"learning_rate\": round(np.random.random(),1),\n#     \"max_depth\": randint(1, 9),\n#     \"subsample\": round(np.random.random(),1),\n#     \"max_features\": randint(1, 9),\n# }\n\nxgb_callbacks = [\n    xgb.callback.EvaluationMonitor(period=25),\n    xgb.callback.EarlyStopping(75, metric_name=\"QWK\", maximize=True, save_best=True)\n]\n\nxgb_regressor = xgb.XGBRegressor(\n    objective=qwk_obj,  # Use custom QWK objective function\n    n_estimators= 207,\n    learning_rate= 0.10704240620854825,\n    min_split_loss = 1,\n    max_depth= 6,\n    subsample= 0.6389081081835488,\n    max_bin = 337,\n    random_state=42,\n    num_leaves = 10,\n    extra_trees=True,\n    class_weight='balanced',\n    tree_method=\"hist\"\n)\n\n# Train the model\nxgb_regressor.fit(X_train, y_train)\n#                 eval_set=[(X_train, y_train), (X_test, y_test)],\n#                 eval_metric=quadratic_weighted_kappa,\n#                 callbacks=xgb_callbacks)\n\n\n# # Make predictions on the validation set\n# y_test_pred = xgb_regressor.predict(X_test)\n\n# # Convert predictions back to the original scale\n# # y_test_pred_original = np.exp(y_test_pred)\n# y_test = y_test + a\n# y_test_pred = (y_test_pred + a).clip(1, 6).round()\n\n\n# # Calculate QWK on the validation set\n# qwk_score = cohen_kappa_score(y_test, y_test_pred_original.round(), weights=\"quadratic\")\n# print(f\"Validation QWK Score: {qwk_score:.4f}\")\n\n# score = quadratic_weighted_kappa(y_test, y_pred)\n# print(f\"Train QWK: {score}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:23:56.517090Z","iopub.execute_input":"2024-05-29T04:23:56.517663Z","iopub.status.idle":"2024-05-29T04:29:33.957468Z","shell.execute_reply.started":"2024-05-29T04:23:56.517631Z","shell.execute_reply":"2024-05-29T04:29:33.956295Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Start running...\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             class_weight='balanced', colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None, device=None,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, extra_trees=True, feature_types=None, gamma=None,\n             grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.10704240620854825,\n             max_bin=337, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=6, max_leaves=None,\n             min_child_weight=None, min_split_loss=1, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=207, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             class_weight=&#x27;balanced&#x27;, colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None, device=None,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, extra_trees=True, feature_types=None, gamma=None,\n             grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.10704240620854825,\n             max_bin=337, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=6, max_leaves=None,\n             min_child_weight=None, min_split_loss=1, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=207, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             class_weight=&#x27;balanced&#x27;, colsample_bylevel=None,\n             colsample_bynode=None, colsample_bytree=None, device=None,\n             early_stopping_rounds=None, enable_categorical=False,\n             eval_metric=None, extra_trees=True, feature_types=None, gamma=None,\n             grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.10704240620854825,\n             max_bin=337, max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=6, max_leaves=None,\n             min_child_weight=None, min_split_loss=1, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=207, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_log = xgb_regressor.predict(X_test)\nprint(y_test)\ny_pred = np.exp(y_pred_log)\nprint(y_pred.round())","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:33.959083Z","iopub.execute_input":"2024-05-29T04:29:33.959572Z","iopub.status.idle":"2024-05-29T04:29:34.237458Z","shell.execute_reply.started":"2024-05-29T04:29:33.959527Z","shell.execute_reply":"2024-05-29T04:29:34.236061Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"12696    1.098612\n4625     1.098612\n733      1.098612\n16885    1.098612\n3334     1.386294\n           ...   \n16145    0.000000\n4229     0.693147\n4313     0.693147\n934      0.693147\n5058     0.693147\nName: score, Length: 3462, dtype: float64\n[4. 4. 2. ... 3. 2. 2.]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Make predictions on the validation set\ny_pred_log = xgb_regressor.predict(X_test)\ny_pred = np.exp(y_pred_log)\n# y_pred = y_pred + a\ny_pred = y_pred.clip(1, 6).round()\ny_test_exp = np.exp(y_test)\n\n# Calculate the Cohen's kappa score\nscore = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\nprint(f\"Train QWK: {score}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.238928Z","iopub.execute_input":"2024-05-29T04:29:34.239528Z","iopub.status.idle":"2024-05-29T04:29:34.517427Z","shell.execute_reply.started":"2024-05-29T04:29:34.239498Z","shell.execute_reply":"2024-05-29T04:29:34.516408Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Train QWK: 0.7725529001484701\n","output_type":"stream"}]},{"cell_type":"code","source":"# def objective(trial):\n#     param_grid = {\n#         'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n#         'min_split_loss': trial.suggest_int('min_split_loss', 0, 9),\n#         'max_depth': trial.suggest_int('max_depth', 6, 12),\n#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n#         'max_bin': trial.suggest_int('max_bin', 256, 512)\n#     }\n\n#     xgb_regressor = xgb.XGBRegressor(\n#         objective=qwk_obj,\n#         random_state=42,\n#         tree_method=\"hist\",\n#         **param_grid\n#     )\n    \n#     xgb_regressor.fit(X_train, y_train)\n    \n#     y_pred_log = xgb_regressor.predict(X_test)\n#     y_pred = np.exp(y_pred_log)\n#     # y_pred = y_pred + a\n#     y_pred = y_pred.clip(1, 6).round()\n#     y_test_exp = np.exp(y_test)\n\n#     # Calculate the Cohen's kappa score\n#     score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n#     return np.mean(score)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.519067Z","iopub.execute_input":"2024-05-29T04:29:34.519400Z","iopub.status.idle":"2024-05-29T04:29:34.524762Z","shell.execute_reply.started":"2024-05-29T04:29:34.519373Z","shell.execute_reply":"2024-05-29T04:29:34.523935Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# # Set up the Optuna study\n# study = optuna.create_study(direction='maximize', sampler=TPESampler())\n# study.optimize(objective, n_trials=40, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.526002Z","iopub.execute_input":"2024-05-29T04:29:34.526490Z","iopub.status.idle":"2024-05-29T04:29:34.534743Z","shell.execute_reply.started":"2024-05-29T04:29:34.526462Z","shell.execute_reply":"2024-05-29T04:29:34.533488Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# # Get the best hyperparameters\n# best_params = study.best_params\n# print(\"Best Hyperparameters:\", best_params)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.536321Z","iopub.execute_input":"2024-05-29T04:29:34.537391Z","iopub.status.idle":"2024-05-29T04:29:34.544716Z","shell.execute_reply.started":"2024-05-29T04:29:34.537357Z","shell.execute_reply":"2024-05-29T04:29:34.543922Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# # Train the final model with the best hyperparameters\n# xgb_regressor = xgb.XGBRegressor(\n#     objective=qwk_obj,\n#     random_state=42,\n#     **best_params\n# )\n\n# xgb_regressor.fit(\n#     X_train, y_train,\n#     early_stopping_rounds=10,\n#     eval_set=[(X_test, y_test)],\n#     verbose=True\n# )\n\n# y_pred_log = xgb_regressor.predict(X_test)\n# y_pred = np.exp(y_pred_log)\n# # y_pred = y_pred + a\n# y_pred = y_pred.clip(1, 6).round()\n# y_test_exp = np.exp(y_test)\n\n# # Calculate the Cohen's kappa score\n# score = cohen_kappa_score(y_test_exp.round(), y_pred, weights='quadratic')\n# print(f\"Train QWK: {score}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.547491Z","iopub.execute_input":"2024-05-29T04:29:34.548352Z","iopub.status.idle":"2024-05-29T04:29:34.556793Z","shell.execute_reply.started":"2024-05-29T04:29:34.548317Z","shell.execute_reply":"2024-05-29T04:29:34.555688Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# df_test = pd.read_csv('/kaggle/input/test-processed-csv/test_processed.csv')\n# df_test\n\ndf_test = preprocess_df(df_test)\ndf_test['clean_text'] = df_test['full_text'].apply(clean_text)\ndf_test = df_test.drop('full_text', axis = 1)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.558394Z","iopub.execute_input":"2024-05-29T04:29:34.559154Z","iopub.status.idle":"2024-05-29T04:29:34.671800Z","shell.execute_reply.started":"2024-05-29T04:29:34.559116Z","shell.execute_reply":"2024-05-29T04:29:34.670629Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"  essay_id  word_count  essay_length  sentences_count  paragraph_count  \\\n0  000d118         545          2677               13                1   \n1  000fe60         371          1669               19                9   \n2  001ab80         605          3077               24                7   \n\n   unique_word_count  text_length_p  word_count_p  unique_word_count_p  \\\n0                248           2640           539                  227   \n1                168           1663           371                  152   \n2                243           3065           605                  231   \n\n   flesch_reading_ease  ...  linsear_write_formula  gunning_fog  \\\n0                58.69  ...              13.000000        17.08   \n1                87.55  ...               6.714286         7.48   \n2                65.15  ...              15.500000        11.49   \n\n   text_standard  spache_readability  mcalpine_efg_time  syllablaw  \\\n0           12.0                7.20              31.58       53.4   \n1            7.0                3.92              19.57       25.7   \n2           12.0                5.12              36.96       32.6   \n\n   readinle_count  lexicon_count  monosyllabcount  \\\n0             624            489              396   \n1             398            332              275   \n2             767            550              417   \n\n                                          clean_text  \n0  many people have car where they live the thing...  \n1  i am a scientist at nasa that is discussing th...  \n2  people always wish they had the same technolog...  \n\n[3 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>word_count</th>\n      <th>essay_length</th>\n      <th>sentences_count</th>\n      <th>paragraph_count</th>\n      <th>unique_word_count</th>\n      <th>text_length_p</th>\n      <th>word_count_p</th>\n      <th>unique_word_count_p</th>\n      <th>flesch_reading_ease</th>\n      <th>...</th>\n      <th>linsear_write_formula</th>\n      <th>gunning_fog</th>\n      <th>text_standard</th>\n      <th>spache_readability</th>\n      <th>mcalpine_efg_time</th>\n      <th>syllablaw</th>\n      <th>readinle_count</th>\n      <th>lexicon_count</th>\n      <th>monosyllabcount</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000d118</td>\n      <td>545</td>\n      <td>2677</td>\n      <td>13</td>\n      <td>1</td>\n      <td>248</td>\n      <td>2640</td>\n      <td>539</td>\n      <td>227</td>\n      <td>58.69</td>\n      <td>...</td>\n      <td>13.000000</td>\n      <td>17.08</td>\n      <td>12.0</td>\n      <td>7.20</td>\n      <td>31.58</td>\n      <td>53.4</td>\n      <td>624</td>\n      <td>489</td>\n      <td>396</td>\n      <td>many people have car where they live the thing...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fe60</td>\n      <td>371</td>\n      <td>1669</td>\n      <td>19</td>\n      <td>9</td>\n      <td>168</td>\n      <td>1663</td>\n      <td>371</td>\n      <td>152</td>\n      <td>87.55</td>\n      <td>...</td>\n      <td>6.714286</td>\n      <td>7.48</td>\n      <td>7.0</td>\n      <td>3.92</td>\n      <td>19.57</td>\n      <td>25.7</td>\n      <td>398</td>\n      <td>332</td>\n      <td>275</td>\n      <td>i am a scientist at nasa that is discussing th...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001ab80</td>\n      <td>605</td>\n      <td>3077</td>\n      <td>24</td>\n      <td>7</td>\n      <td>243</td>\n      <td>3065</td>\n      <td>605</td>\n      <td>231</td>\n      <td>65.15</td>\n      <td>...</td>\n      <td>15.500000</td>\n      <td>11.49</td>\n      <td>12.0</td>\n      <td>5.12</td>\n      <td>36.96</td>\n      <td>32.6</td>\n      <td>767</td>\n      <td>550</td>\n      <td>417</td>\n      <td>people always wish they had the same technolog...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Lưu lại cột essay_id để sử dụng sau này\nessay_ids = df_test['essay_id']\n\n# Xóa cột essay_id trước khi tiền xử lý\nX_test = df_test.drop('essay_id', axis=1)\n\n# Áp dụng pipeline đã huấn luyện để tiền xử lý dữ liệu test\nX_test_preprocessed = pipeline.transform(X_test)\n\n# Dự đoán điểm số trên dữ liệu test đã tiền xử lý\ny_pred_log = xgb_regressor.predict(X_test_preprocessed)\n\n# Chuyển đổi ngược từ log-transform\ny_pred = np.exp(y_pred_log)\n\n# Tạo dataframe chứa essay_id và dự đoán điểm số\nresults = pd.DataFrame({'essay_id': essay_ids, 'score': y_pred})\n\n# Làm tròn điểm số\nresults['score'] = round(results['score'])\nresults['score'] = results['score'].astype(int)\n\n# Lưu kết quả ra file csv\nsubmission = results.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.673348Z","iopub.execute_input":"2024-05-29T04:29:34.674103Z","iopub.status.idle":"2024-05-29T04:29:34.746560Z","shell.execute_reply.started":"2024-05-29T04:29:34.674057Z","shell.execute_reply":"2024-05-29T04:29:34.745629Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-05-29T04:29:34.747980Z","iopub.execute_input":"2024-05-29T04:29:34.748935Z","iopub.status.idle":"2024-05-29T04:29:34.759097Z","shell.execute_reply.started":"2024-05-29T04:29:34.748902Z","shell.execute_reply":"2024-05-29T04:29:34.757900Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"  essay_id  score\n0  000d118      3\n1  000fe60      3\n2  001ab80      4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000d118</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fe60</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001ab80</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}