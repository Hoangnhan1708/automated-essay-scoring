{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71485,"databundleVersionId":8059942,"sourceType":"competition"},{"sourceId":8409194,"sourceType":"datasetVersion","datasetId":5004567},{"sourceId":8409621,"sourceType":"datasetVersion","datasetId":5004904}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport re\ncmap = plt.cm.get_cmap('coolwarm')\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Use for pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nfrom xgboost import XGBRegressor\nfrom xgboost import XGBClassifier \nfrom sklearn.model_selection import GridSearchCV, KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-19T02:51:48.590666Z","iopub.execute_input":"2024-05-19T02:51:48.591064Z","iopub.status.idle":"2024-05-19T02:51:52.122858Z","shell.execute_reply.started":"2024-05-19T02:51:48.591027Z","shell.execute_reply":"2024-05-19T02:51:52.121474Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1794285695.py:11: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n  cmap = plt.cm.get_cmap('coolwarm')\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/test-processed-csv/test_processed.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/sample_submission.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv\n/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv\n/kaggle/input/train-processed-csv/train_processed.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/train.csv')\ndf_test = pd.read_csv('/kaggle/input/learning-agency-lab-automated-essay-scoring-2/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:57:48.350457Z","iopub.execute_input":"2024-05-19T02:57:48.350949Z","iopub.status.idle":"2024-05-19T02:57:48.872483Z","shell.execute_reply.started":"2024-05-19T02:57:48.350914Z","shell.execute_reply":"2024-05-19T02:57:48.870966Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"essay_id_dropped = df_train['essay_id']\ndf_train = df_train.drop('essay_id', axis = 1)\ndf_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:57:49.819343Z","iopub.execute_input":"2024-05-19T02:57:49.819842Z","iopub.status.idle":"2024-05-19T02:57:49.843395Z","shell.execute_reply.started":"2024-05-19T02:57:49.819804Z","shell.execute_reply":"2024-05-19T02:57:49.841734Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17307 entries, 0 to 17306\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   full_text  17307 non-null  object\n 1   score      17307 non-null  int64 \ndtypes: int64(1), object(1)\nmemory usage: 270.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Number of words\ndef preprocess_df(df):\n    df['word_count'] = df['full_text'].apply(lambda x: len(x.split()))\n\n    # Length\n    df['essay_length'] = df['full_text'].str.len()\n\n    # Sentences count\n    # Adding a new column 'sentences_count' that counts the sentences in 'full_text'\n    df['sentences_count'] = df['full_text'].str.count(r'\\.')\n\n    # Paragraph count\n    # Adding a new column 'paragraph_count' that counts the paragraphs in 'full_text'\n    df['paragraph_count'] = df['full_text'].str.count(r'\\n') + 1\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:57:51.554833Z","iopub.execute_input":"2024-05-19T02:57:51.555356Z","iopub.status.idle":"2024-05-19T02:57:51.563023Z","shell.execute_reply.started":"2024-05-19T02:57:51.555304Z","shell.execute_reply":"2024-05-19T02:57:51.561879Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"cList = {\n  \"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",  \"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\n  \"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\"he's\": \"he is\",\n  \"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how is\",\"I'd\": \"I would\",\"I'd've\": \"I would have\",\"I'll\": \"I will\",\"I'll've\": \"I will have\",\"I'm\": \"I am\",\"I've\": \"I have\",\n  \"isn't\": \"is not\",\"it'd\": \"it had\",\"it'd've\": \"it would have\",\"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\",\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n  \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n  \"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n  \"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"so's\": \"so is\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\"that's\": \"that is\",\"there'd\": \"there had\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we had\",\n  \"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n  \"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\n  \"what're\": \"what are\",\"what's\": \"what is\",\"what've\": \"what have\",\"when's\": \"when is\",\"when've\": \"when have\",\n  \"where'd\": \"where did\",\"where's\": \"where is\",\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who's\": \"who is\",\"who've\": \"who have\",\"why's\": \"why is\",\n  \"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\"would've\": \"would have\",\"wouldn't\": \"would not\",\n  \"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\"y'alls\": \"you alls\",\"y'all'd\": \"you all would\",\n  \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you had\",\"you'd've\": \"you would have\",\"you'll\": \"you you will\",\"you'll've\": \"you you will have\",\"you're\": \"you are\",  \"you've\": \"you have\"\n   }\n\nc_re = re.compile('(%s)' % '|'.join(cList.keys()))\n\ndef expandContractions(text, c_re=c_re):\n    def replace(match):\n        return cList[match.group(0)]\n    return c_re.sub(replace, text)\n\ndef removeHTML(x):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',x)\ndef dataPreprocessing(x):\n    x = x.lower()\n    x = removeHTML(x)\n    x = re.sub(\"@\\w+\", '',x)\n    x = re.sub(\"'\\d+\", '',x)\n    x = re.sub(\"\\d+\", '',x)\n    x = re.sub(\"http\\w+\", '',x)\n    x = re.sub(r\"\\s+\", \" \", x)\n#     x = expandContractions(x)\n    x = re.sub(r\"\\.+\", \".\", x)\n    x = re.sub(r\"\\,+\", \",\", x)\n    x = x.strip()\n    return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = preprocess_df(df_train)\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:57:52.243213Z","iopub.execute_input":"2024-05-19T02:57:52.244958Z","iopub.status.idle":"2024-05-19T02:57:52.872551Z","shell.execute_reply.started":"2024-05-19T02:57:52.244905Z","shell.execute_reply":"2024-05-19T02:57:52.871063Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                           full_text  score  word_count  \\\n0  Many people have car where they live. The thin...      3         498   \n1  I am a scientist at NASA that is discussing th...      3         332   \n2  People always wish they had the same technolog...      4         550   \n3  We all heard about Venus, the planet without a...      4         451   \n4  Dear, State Senator\\n\\nThis is a letter to arg...      3         373   \n\n   essay_length  sentences_count  paragraph_count  \n0          2677               13                1  \n1          1669               19                9  \n2          3077               24                7  \n3          2701               23                9  \n4          2208               15               11  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>full_text</th>\n      <th>score</th>\n      <th>word_count</th>\n      <th>essay_length</th>\n      <th>sentences_count</th>\n      <th>paragraph_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Many people have car where they live. The thin...</td>\n      <td>3</td>\n      <td>498</td>\n      <td>2677</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I am a scientist at NASA that is discussing th...</td>\n      <td>3</td>\n      <td>332</td>\n      <td>1669</td>\n      <td>19</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>People always wish they had the same technolog...</td>\n      <td>4</td>\n      <td>550</td>\n      <td>3077</td>\n      <td>24</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>We all heard about Venus, the planet without a...</td>\n      <td>4</td>\n      <td>451</td>\n      <td>2701</td>\n      <td>23</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n      <td>3</td>\n      <td>373</td>\n      <td>2208</td>\n      <td>15</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Tìm các dòng có giá trị LotFrontage lớn hơn 300 và lấy index của chúng\n\nrows_to_drop = df_train.query('sentences_count > 60 | (sentences_count > 50 & score == 1)').index\n\n# Xóa các dòng có index tương ứng\n\ndf_train.drop(rows_to_drop, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:57:55.240396Z","iopub.execute_input":"2024-05-19T02:57:55.240944Z","iopub.status.idle":"2024-05-19T02:57:55.258276Z","shell.execute_reply.started":"2024-05-19T02:57:55.240904Z","shell.execute_reply":"2024-05-19T02:57:55.256886Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Tìm các dòng có giá trị LotFrontage lớn hơn 300 và lấy index của chúng\n\nrows_to_drop = df_train.query('paragraph_count > 80 | (paragraph_count > 55 & score == 1 ) | (paragraph_count >60 & score == 2 ) | (paragraph_count > 30  & score == 5) | (paragraph_count > 25  & score == 6)').index\n\n# Xóa các dòng có index tương ứng\n\ndf_train.drop(rows_to_drop, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:57:56.355046Z","iopub.execute_input":"2024-05-19T02:57:56.355538Z","iopub.status.idle":"2024-05-19T02:57:56.376264Z","shell.execute_reply.started":"2024-05-19T02:57:56.355500Z","shell.execute_reply":"2024-05-19T02:57:56.374849Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Define transformers for numerical and categorical columns\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse = False))\n])\n\n# Update categorical and numerical columns\nnumerical_columns = df_train.select_dtypes('int64').columns\ncategorical_columns = df_train.select_dtypes('object').columns\n\n# Remove target variable from numerical columns\nnumerical_columns = numerical_columns.drop('score')\n\n# Combine transformers using ColumnTransformer\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_columns),\n        ('cat', categorical_transformer, categorical_columns)\n    ],remainder = 'passthrough')\n\n# Create a pipeline with the preprocessor\npipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor)])\n\n# Apply the pipeline to your dataset\nX = df_train.drop('score', axis=1)\ny = np.log(df_train['score']) #normalize dependent variable \nX_preprocessed = pipeline.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:57:58.631574Z","iopub.execute_input":"2024-05-19T02:57:58.632055Z","iopub.status.idle":"2024-05-19T02:58:01.097888Z","shell.execute_reply.started":"2024-05-19T02:57:58.632022Z","shell.execute_reply":"2024-05-19T02:58:01.096690Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# from sklearn.feature_extraction.text import TfidfVectorizer\n# # Chuyển đổi văn bản thành đặc trưng sử dụng TF-IDF\n# vectorizer = TfidfVectorizer()\n# X = vectorizer.fit_transform(df['full_text'])\n# y = df['score'] - 1","metadata":{"execution":{"iopub.status.busy":"2024-05-14T11:31:53.029267Z","iopub.execute_input":"2024-05-14T11:31:53.029727Z","iopub.status.idle":"2024-05-14T11:31:53.035284Z","shell.execute_reply.started":"2024-05-14T11:31:53.029694Z","shell.execute_reply":"2024-05-14T11:31:53.033968Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, \n                                                    test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:58:01.184115Z","iopub.execute_input":"2024-05-19T02:58:01.184539Z","iopub.status.idle":"2024-05-19T02:58:02.151760Z","shell.execute_reply.started":"2024-05-19T02:58:01.184507Z","shell.execute_reply":"2024-05-19T02:58:02.150456Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Define the models\nmodels = {\n    'XGBoost': XGBRegressor(random_state=42),\n}\n\n# Define the hyperparameter grids for each model\nparam_grids = {\n    'XGBoost': {\n        'n_estimators': [100],\n        'learning_rate': [0.1],\n        'max_depth': [3],\n        'subsample': [1.0],\n    }\n}\n\n# 3-fold cross-validation\ncv = KFold(n_splits=3, shuffle=True, random_state=42)\n\n# Train and tune the models\ngrids = {}\nfor model_name, model in models.items():\n    grids[model_name] = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n    grids[model_name].fit(X_train, y_train)\n    best_params = grids[model_name].best_params_\n    best_score = np.sqrt(-1 * grids[model_name].best_score_)\n    \n    print(f'Best parameters for {model_name}: {best_params}')\n    print(f'Best RMSE for {model_name}: {best_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:54:23.773940Z","iopub.execute_input":"2024-05-19T02:54:23.774468Z","iopub.status.idle":"2024-05-19T02:57:10.696178Z","shell.execute_reply.started":"2024-05-19T02:54:23.774428Z","shell.execute_reply":"2024-05-19T02:57:10.694779Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 1 candidates, totalling 3 fits\nBest parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1.0}\nBest RMSE for XGBoost: 0.2943404135826672\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# df_test = pd.read_csv('/kaggle/input/test-processed-csv/test_processed.csv')\n# df_test\n\ndf_test = preprocess_df(df_test)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:58:38.983441Z","iopub.execute_input":"2024-05-19T02:58:38.983909Z","iopub.status.idle":"2024-05-19T02:58:39.000111Z","shell.execute_reply.started":"2024-05-19T02:58:38.983866Z","shell.execute_reply":"2024-05-19T02:58:38.998839Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"  essay_id                                          full_text  word_count  \\\n0  000d118  Many people have car where they live. The thin...         498   \n1  000fe60  I am a scientist at NASA that is discussing th...         332   \n2  001ab80  People always wish they had the same technolog...         550   \n\n   essay_length  sentences_count  paragraph_count  \n0          2677               13                1  \n1          1669               19                9  \n2          3077               24                7  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>full_text</th>\n      <th>word_count</th>\n      <th>essay_length</th>\n      <th>sentences_count</th>\n      <th>paragraph_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000d118</td>\n      <td>Many people have car where they live. The thin...</td>\n      <td>498</td>\n      <td>2677</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fe60</td>\n      <td>I am a scientist at NASA that is discussing th...</td>\n      <td>332</td>\n      <td>1669</td>\n      <td>19</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001ab80</td>\n      <td>People always wish they had the same technolog...</td>\n      <td>550</td>\n      <td>3077</td>\n      <td>24</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Apply the pipeline to dataset\nX_test_preprocessed = pipeline.transform(df_test)\n\n# Lấy mô hình tốt nhất\nbest_model = grids['XGBoost'].best_estimator_\nbest_model","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:58:40.501088Z","iopub.execute_input":"2024-05-19T02:58:40.501577Z","iopub.status.idle":"2024-05-19T02:58:40.574237Z","shell.execute_reply.started":"2024-05-19T02:58:40.501540Z","shell.execute_reply":"2024-05-19T02:58:40.573098Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=3, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=100, n_jobs=None,\n             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# Lưu lại cột essay_id để sử dụng sau này\nessay_ids = df_test['essay_id']\n\n# Xóa cột essay_id trước khi tiền xử lý\nX_test = df_test.drop('essay_id', axis=1)\n\n# Áp dụng pipeline đã huấn luyện để tiền xử lý dữ liệu test\nX_test_preprocessed = pipeline.transform(X_test)\n\n# Dự đoán điểm số trên dữ liệu test đã tiền xử lý\ny_pred_log = grids['XGBoost'].predict(X_test_preprocessed)\n\n# Chuyển đổi ngược từ log-transform\ny_pred = np.exp(y_pred_log)\n\n# Tạo dataframe chứa essay_id và dự đoán điểm số\nresults = pd.DataFrame({'essay_id': essay_ids, 'score': y_pred})\n\n# Làm tròn điểm số\nresults['score'] = round(results['score'])\nresults['score'] = results['score'].astype(int)\n\n# Lưu kết quả ra file csv\nsubmission = results.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:58:42.596555Z","iopub.execute_input":"2024-05-19T02:58:42.597558Z","iopub.status.idle":"2024-05-19T02:58:42.714889Z","shell.execute_reply.started":"2024-05-19T02:58:42.597504Z","shell.execute_reply":"2024-05-19T02:58:42.710528Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2024-05-19T02:58:45.765265Z","iopub.execute_input":"2024-05-19T02:58:45.765946Z","iopub.status.idle":"2024-05-19T02:58:45.779233Z","shell.execute_reply.started":"2024-05-19T02:58:45.765896Z","shell.execute_reply":"2024-05-19T02:58:45.777612Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"  essay_id  score\n0  000d118      3\n1  000fe60      3\n2  001ab80      4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>essay_id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000d118</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fe60</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001ab80</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time= 1.7min\n[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time= 1.7min\n[CV] END learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0; total time= 1.9min\n","output_type":"stream"}]}]}